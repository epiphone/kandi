% !TeX encoding = utf8
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL tp2/kandiTP2-23-11.tex   Thu Nov 21 21:29:58 2013
%DIF ADD kandi_tyoversio.tex      Wed Nov 27 22:33:23 2013
%
% [ Tiedostossa k채ytetty merkist철 on utf8, vaihtoehtoisesti voisi olla esim.]
% [ ISO 8859-1 eli Latin 1. Yll채oleva rivi ]
% [ tarvitaan, jos k채ytt채채 MiKTeX-paketin mukana tulevaa TeXworks-editoria. ]
%
% TIETOTEKNIIKAN KANDIDAATINTUTKIELMA
%
% Yksinkertainen LaTeX2e-mallipohja kandidaatintutkielmalle.
% K채ytt채채 Antti-Juhani Kaijanahon kirjoittamaa gradu3-dokumenttiluokkaa.
%
% Jos kirjoitat pro gradu -tutkielmaa, tee mallipohjaan seuraavat muutokset:
%  - Poista dokumenttiluokasta optio bachelor .
%  - Poista makro \type .
%  - Lis채채 suuntautumisvaihtoehto makrolla \studyline .
%  - Lis채채 tieto ohjaajasta makrolla \supervisor .

\documentclass[utf8,bachelor,manualbib]{gradu3}

\usepackage{palatino} % valitaan oletusfonttia hieman tyylikk채채mpi fontti

\usepackage{graphicx} % tarvitaan vain, jos halutaan mukaan kuvia
\usepackage{amsmath}  % tarvitaan k채ytett채ess채 monimutkaisten matemaattisten kaavojen ja \eqref-kaavaviittauksen yhteydess채
\usepackage{url} % tarvitaan \url-komentoa varten
\usepackage{booktabs}

\usepackage{amsfonts}
\usepackage{enumitem}

% Otetaan k채ytt철철n author-date-j채rjestelm채n mukaiset l채hdeviittaukset:
\usepackage{natbib}
% Vaihdetaan kirjoittajan nimen ja vuosiluvun v채liseksi erottimeksi
% v채lily철nti (oletuserottimena on pilkku):
%\bibpunct{(}{)}{;}{a}{}{,}

\newcommand{\argmax}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{max}}\;}

% HUOM! T채m채n tulee olla viimeinen \usepackage koko dokumentissa!
\usepackage[bookmarksopen,bookmarksnumbered,linktocpage]{hyperref}

%\addbibresource{viite.bib}% L채hdetietokannan tiedostonimi
%http://www.tex.ac.uk/tex-archive/macros/latex/exptl/biblatex-contrib/biblatex-chicago/latex/biblatex-chicago.sty
%http://www.tex.ac.uk/tex-archive/macros/latex/contrib/etoolbox/etoolbox.sty
%http://mirrors.med.harvard.edu/ctan/macros/latex/contrib/biblatex/latex/biblatex.sty
%http://ctan.mackichan.com/macros/latex/contrib/biblatex/latex/biblatex2.sty
%http://mirror.hmc.edu/ctan/macros/latex/contrib/logreq/logreq.sty
%https://github.com/Martin-Rotter/qt-survival-guide/blob/master/logreq.def

%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}

\title{Sanaluokkien automaattisen tunnistamisen menetelm채t}

\translatedtitle{Methods for automated part-of-speech tagging}

%\studyline{}
\DIFdelbegin %DIFDELCMD < \avainsanat{luonnollisten kielten k채sittely, sanaluokkien tunnistaminen, koneoppiminen}
%DIFDELCMD < \keywords{natural language processing, part-of-speech tagging, machine learning}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \avainsanat{kieliteknologia, luonnollisten kielten k채sittely, sanaluokkien tunnistaminen, koneoppiminen}
\keywords{computational linguistics, natural language processing, part-of-speech tagging, machine learning}
\DIFaddend \tiivistelma{Tiivistelm채 on tyypillisesti 5-10 rivi채 pitk채 esitys ty철n p채채kohdista (tausta, tavoite, tulokset, johtop채채t철kset).
}
\abstract{Englanninkielinen versio tiivistelm채st채.
}

\author{Aleksi Pekkala}
\contactinformation{\texttt{aleksi.v.a.pekkala@student.jyu.fi}}
% jos useita tekij철it채, anna useampi \author-komento
%\supervisor{Kirsi Valjus}
% jos useita ohjaajia, anna useampi \supervisor-komento
%\type{kandidaatintutkielma} % t채m채n makron oletus on "pro gradu -tutkielma" ja bachelor-optiolla kandidaatintutkielma

\maketitle

\mainmatter


\chapter{Johdanto}


Sanaluokkien automaattinen tunnistaminen (engl. \emph{part-of-speech tagging}) tarkoittaa sanojen sanaluokkien tunnistamista tekstiyhteyden perusteella.  Tunnistamisprosessissa tarkastellaan tekstiaineistoa, kuten

\[a\:black\:cat\:jumped\:on\:the\:table\]

jonka perusteella pyrit채채n p채채ttelem채채n se sanaluokkien sarja, joka todenn채k철isimmin vastaa kyseist채 aineistoa; t채ss채 tapauksessa tuloksena voisi olla esimerkiksi

\[Det\:Adj\:Noun\:Verb\:Prep\:Det\:Noun\]

Sanaluokkien tunnistaminen on laajuudeltaan rajallinen ongelma: sen tarkoituksena ei ole j채sent채채 kokonaisia lauserakenteita tai tulkita lauseiden merkityst채 --- tarkastelun alla ovat vain yksitt채isten sanojen syntaktiset kategoriat. Sanaluokkien tunnistaminen on kuitenkin v채ltt채m채t철n ensimm채inen askel useimmissa luonnollisten kielten k채sittelyprosesseissa, ja siten yksi aihealueen keskeisimmist채 osaongelmista.

Rajallisen laajuutensa my철t채 sanaluokkien tunnistaminen on paljon helpommin l채hestytt채v채 ongelma kuin kielen t채ydellinen ymm채rt채minen, ja sen ratkaisemiseksi onkin kehitetty useita kohtuullisen luotettavia menetelmi채. T채ysin ratkaistusta ongelmasta ei kuitenkaan voida puhua, sill채 yksik채채n tunnettu menetelm채 ei viel채 saavuta t채ydellist채 tunnistustarkkuutta.

Sanaluokkien tunnistajia k채ytet채채n monissa erilaisissa luonnollisiin kieliin liittyviss채 sovelluksissa, ja tunnistajalle asetetut vaatimukset vaihtelevat sovelluksittain. My철s tunnistettavien aineistojen v채lill채 on valtavasti poikkeamia, esim. kielten sek채 tekstilajien osalta. Lis채ksi havaitaan, ett채 nykyisten tunnistusmenetelmien saavuttamat tunnistustarkkuudet liikkuvat kaikki suunnilleen samoissa lukemissa. Kun ilmiselvin valintakriteeri on n채in poissuljettu, on tehokkaimman menetelm채n valinta vaikeampaa. Tunnistusmenetelmien toimintaperiaatteiden vaihdellessa merkitt채v채sti on kuitenkin v채ist채m채t철nt채, ett채 jotkin menetelm채t soveltuvat toisia paremmin tiettyihin tunnistusteht채viin. T채ss채 tutkielmassa pyrit채채nkin selvent채m채채n sit채, \DIFdelbegin \DIFdel{kuinka eri tunnistusmenetelm채t k채ytt채ytyv채t suhteessa toisiinsa erilaisissa toimintaymp채rist철iss채, }\DIFdelend \DIFaddbegin \DIFadd{millaisia eri ratkaisuja sanaluokkien tunnistusongelmaan on olemassa }\DIFaddend ja mitk채 ovat niiden \DIFdelbegin \DIFdel{oleellisimmat vahvuudet sek}\DIFdelend \DIFaddbegin \DIFadd{t}\DIFaddend \DIFdelbegin \DIFdel{heikkoudet}\DIFdelend \DIFaddbegin \DIFadd{rkeimm채t erot}\DIFaddend . Menetelmien suhteelliset ominaisuudet johdetaan tarkastelemalla l채hemmin kunkin menetelm채n toimintaa \DIFdelbegin \DIFdel{, }\DIFdelend sek채 menetelm채채n liittyv채채 tutkimuskirjallisuutta. 

Tutkielma rakentuu seuraavasti: toisessa luvussa annetaan lyhyt johdanto sanaluokkien tunnistamiseen ja sen haasteisiin. Luvuissa 3-5 tarkastellaan kolmea erilaista tunnistusmenetelm채채\DIFdelbegin \DIFdel{, }\DIFdelend \DIFaddbegin \DIFadd{: transformaatios채채nt철j채, Markovin piilomalleja sek채 log-lineaarisia malleja. Luvuissa }\DIFaddend esitell채채n \DIFdelbegin \DIFdel{niiden }\DIFdelend \DIFaddbegin \DIFadd{menetelmien }\DIFaddend keskeiset ominaisuudet, \DIFdelbegin \DIFdel{ja }\DIFdelend \DIFaddbegin \DIFadd{sek채 }\DIFaddend pyrit채채n hahmottamaan \DIFdelbegin \DIFdel{kunkin menetelm}\DIFdelend \DIFaddbegin \DIFadd{niiden suhteelliset vahvuudet ja heikkoudet. Lopuksi viel}\DIFaddend  \DIFdelbegin \DIFdel{n suhteelliset vahvuudet . TODO mainitaan }\DIFdelend \DIFaddbegin \DIFadd{kootaan yhteen menetelmist채 ker채tyt huomiot ja esitell채채n johtop채채t철kset.
}

\DIFadd{TODO olisiko syyt채 esitell채 }\DIFaddend lyhyesti valitut menetelm채t \DIFdelbegin \DIFdel{ja valintaperusteet (}\DIFdelend \DIFaddbegin \DIFadd{t채ss채, ja/tai mainita jotain valintaperusteista tai }\DIFaddend esitysj채rjestyksest채 \DIFdelbegin \DIFdel{: }\DIFdelend \DIFaddbegin \DIFadd{(}\DIFaddend kaksi ensimm채ist채 ovat tavallaan toistensa vastakohtia, ja kolmas menetelm채 yhdist채채 piirteit채 kummastakin aikaisemmasta menetelm채st채. Samalla menetelm채t ovat j채rjestetty yksinkertaisimmasta monimutkaisimpaan.).


\chapter{Sanaluokkien automaattinen tunnistaminen}

\DIFdelbegin \section{\DIFdel{Mihin sanaluokkien tunnistamista k채ytet채채n?}}
%DIFAUXCMD
\addtocounter{section}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend Sanaluokkien tunnistaminen on t채rke채 ja k채yt채nn철llinen ongelma, joka kohdataan \DIFdelbegin \DIFdel{useimmissa }\DIFdelend \DIFaddbegin \DIFadd{l채hes kaikissa }\DIFaddend luonnollisten kielten k채sittelyyn liittyviss채 teht채viss채. T채llaisia teht채vi채 ovat mm. puheentunnistus, konek채채nt채minen sek채 semanttinen haku ja analyysi. Kyseisiss채 teht채viss채 sanaluokkien tunnistaja toimii jonkin laajemman prosessointiketjun alkup채채ss채, koko prosessille v채ltt채m채tt철m채n채 esik채sittelij채n채, joka mahdollistaa sy철tteen jatkok채sittelyn korkeammalla tasolla. Jatkok채sittelyn tyypillisin seuraava vaihe on tekstin j채sent채minen eli lauserakenteiden tunnistaminen. Oikeiden lauserakenteiden tunnistamisen kannalta on oleellista, ett채 lauseiden sanaluokat on tunnistettu mahdollisimman virheett철m채sti: yksikin virheellinen sanaluokka voi tehd채 oikean lauserakenteen tunnistamisesta mahdotonta, ja siten v채채rist채채 lauseen tulkittua merkityst채.


\section{Sanaluokkien tunnistamisen lyhyt historia}

TODO


\section{Miksi sanaluokkien tunnistaminen on ongelmallista?}

Sanaluokkien tunnistaminen voi intuitiivisesti tuntua helpolta, mutta teht채v채n automaatiota hankaloittavat kaksi oleellista ongelmaa: sanojen monitulkintaisuus sek채 tuntemattomat sanat. Esimerkiksi lauseet
\DIFaddbegin \DIFadd{TODO back door, back of my foot - esimerkki, josta ilmenee sanaluokan monitulk.
}\DIFaddend \[Time\: flies\: like\: an\: arrow\]
\[Fruit\: flies\: like\: a\: banana\]
voidaan tulkita lukuisin eri tavoin, joista mik채채n ei ole v채ltt채m채tt채 muita ilmeisempi. Lis채ksi, vaikka tosiel채m채ss채 tulkittavat lauseet ovat harvoin yht채 ongelmallisia kuin edell채mainitut lingvistiset esimerkkilauseet, on monitulkintaisuus hyvin yleist채: arviolta 40\% englanninkielisen proosan sanastosta \DIFdelbegin \DIFdel{omaa useamman kuin yhden merkityksen \mbox{%DIFAUXCMD
\citep{derose1988}
}%DIFAUXCMD
. 
}\DIFdelend \DIFaddbegin \DIFadd{voidaan luokitella useampaan kuin yhteen sanaluokkaan \mbox{%DIFAUXCMD
\citep{derose1988}
}%DIFAUXCMD
. 
}

\DIFaddend Jatkok채sittelyn kannalta automaattisen tunnistajan oleellisin teht채v채 onkin \DIFdelbegin \DIFdel{sen sopivimman merkityksen valinta, eli ns. morfologinen }\DIFdelend \DIFaddbegin \DIFadd{valita kaikista mahdollisista sanaluokista se, joka tuottaa luontevimman tulkinnan. T채llaisen }\DIFaddend yksik채sitteist채\DIFdelbegin \DIFdel{minen. Yksik채sitteist채}\DIFdelend misen mahdollistavat luonnollisten kielten sis채채nrakennetut rajoitteet, \DIFdelbegin \DIFdel{ja erityisesti kaksi oleellista vihjetyyppi}\DIFdelend \DIFaddbegin \DIFadd{jotka voidaan jakaa lokaaleihin sek}\DIFaddend  \DIFdelbegin \DIFdel{: lokaalit vihjeet }\DIFdelend \DIFaddbegin \DIFadd{kontekstuaalisiin vihjeisiin: lokaaleista vihjeist채 ilmeisin on itse sana }\DIFaddend (''sana \textit{can} on \DIFaddbegin \DIFadd{on }\DIFaddend todenn채k철isemmin modaaliverbi kuin substantiivi''), \DIFaddbegin \DIFadd{mutta p채채telmi채 voidaan tehd채 my철s esimerkiksi sanan prefiksin, suffiksin }\DIFaddend sek채 \DIFdelbegin \DIFdel{kontekstuaaliset vihjeet (''}\DIFdelend \DIFaddbegin \DIFadd{alkukirjaimen koon perusteella. Kontekstuaalisia vihjeit채 ovat kaikki lauseen muut sanat sanaluokkineen: esimerkiksi }\DIFaddend sana \textit{fly} on todenn채k철isimmin substantiivi, jos edelt채v채 sana on artikkeli\DIFdelbegin \DIFdel{'')}\DIFdelend .

\DIFaddbegin \DIFadd{On t채rke채채 huomata, ettei sanaluokkien tunnistaminen itsess채채n ole ratkaisu kieliopilliseen monitulkintaisuuteen: monitulkintaisuudella on useita tasoja, joista osaa k채sitell채채n viel채 prosessointiketjun my철hemmiss채 vaiheissa. Esimerkiksi syntaktinen, tai rakenteellinen monitulkintaisuus on ongelma, joka on huomattavasti helpompi ratkaista lauseiden j채sennyksen yhteydess채. Sanaluokkien tunnistamista ei my철sk채채n tule sekoittaa semanttiseen yksik채sitteist채miseen, eli sanan merkityksen selvitt채miseen: esimerkiksi sana }\textit{\DIFadd{mouse}} \DIFadd{on semanttisesti monitulkintainen, vaikka sen sanaluokka tunnettaisiinkin. Sanaluokkien tunnistusprosessin rooli on pikemminkin rajata mahdollisten tulkintojen m채채r채채 prosessointiketjun alkup채채ss채, jotta my철hemmiss채 vaiheissa v채ltyt채채n turhalta ty철lt채.
}

\DIFaddend Toinen merkitt채v채 ongelma on tuntemattomien, eli harjoitusaineistosta puuttuvien sanojen k채sitteleminen \DIFdelbegin \DIFdel{. Tuntemattomia sanoja }\DIFdelend \DIFaddbegin \DIFadd{(TODO: onko t채m채 ymm채rrett채v채 selitys? harjoitusaineistosta tai ohjatusta oppimisesta ei ole viel채 mainittu mit채채n). Englannin kieless채 yleisi채 tuntemattomia sanoja ovat erisnimet sek채 puhekieliset, vieraskieliset ja muut harvinaiset ilmaisut. T채llaisia sanoja }\DIFaddend kohdataan usein, ja koska niit채 koskevaa tilastollista informaatiota tai s채채nt철j채 ei tunneta, joudutaan turvautumaan jonkinlaiseen poikkeusk채sittelyyn. Useat tunnistajat hy철dynt채v채t tuntemattomien sanojen kohdalla kieliopillisia ominaisuuksia: yksinkertainen menetelm채 on m채채r채t채 sanalle se sanaluokka, joihin tuntemattomien sanojen on havaittu todenn채k철isimmin kuuluvan, eli yleens채 substantiivi. Parempia tuloksia on saavutettu m채채ritt채m채ll채 tuntemattoman sanan sanaluokka sen p채채tteen perusteella; esim. englannin kielen \emph{able}-p채채tteiset sanat ovat hyvin todenn채k철isesti adjektiiveja \citep{samuelsson1993}. Menetelm채 ei kuitenkaan sovellu kaikille kielille: esim. \citet{tseng2005} osoittavat, ett채 kiinan kieless채 esiintyy huomattavan suuri m채채r채 yleisi채 affikseja, poiketen englannin ja saksan kielist채, joissa affiksit ovat vahva indikaattori sanan sanaluokasta.


\DIFdelbegin \DIFdel{Ongelmallista on my철s tunnistamisessa k채ytett채vien sanaluokkien (engl. }\emph{\DIFdel{POS tagset}}%DIFAUXCMD
\DIFdel{) valinta. Yleisi채 englannin kielen sanaluokkasettej채 ovat Brownin aineiston 87 sanaluokkaa \mbox{%DIFAUXCMD
\citep{francis1964}
}%DIFAUXCMD
, tai uudemman Penn Treebank-aineiston 48 sanaluokkaa \mbox{%DIFAUXCMD
\citep{marcus1993}
}%DIFAUXCMD
. My철s yleisi채, kielest채 riippumattomia sanaluokkasettej채 on kehitetty, joskin t채ll철in joudutaan v채ist채m채tt채 tinkim채채n tunnistamistarkkuudesta \mbox{%DIFAUXCMD
\citep{petrov2011}
}%DIFAUXCMD
.
}%DIFDELCMD < 

%DIFDELCMD < 
%DIFDELCMD < %%%
\DIFdelend \section{Automaattisten tunnistajien suorituskyky}

Kuten mainittua, nykyisten automaattisten sanaluokkien tunnistajien tunnistustarkkuus --- englanninkielist채 kirjakielt채 analysoitaessa --- on hieman yli 97\%  (\citealp{toutanova2003}, \citealp{shen2007}, \citealp{spoustova2009}, \citealp{sogaard2010}). \citet{manning2011} kuitenkin osoittaa, ett채 kyseist채 tulosta ei ole syyt채 tulkita liian optimistisesti: esimerkiksi lukuisat v채likemerkit ja muut yksik채sitteiset elementit v채채rist채v채t evaluaatiotuloksia. Lis채ksi useissa tekstilajeissa, kuten uutisiartikkeleissa, lauseiden keskipituus on yli 20 sanaa, jolloin edell채mainitullakin tunnistustarkkuudella jokaisessa lauseessa on keskim채채rin ainakin yksi virhe \citep{manning1999}. Artikkelissa huomautetaankin, ett채 realistisempaa olisi tarkastella automaattisten tunnistajien kyky채 tunnistaa kokonaiset lauseet oikein, sill채 pienikin virhe lauseessa voi vahingoittaa tunnistajan hy철dyllisyytt채 my철hempien prosessointivaiheiden kannalta; t채ll채 saralla tunnistajat saavuttavat noin 55-57\% tarkkuuden, mik채 on huomattavasti vaatimattomampi tulos.

Tarkkuustuloksia arvioidessa tulee my철s ottaa huomioon varsin korkea l채ht철taso: jo yksinkertaisimmalla metodilla, eli valitsemalla kullekin sanalle se sanaluokka, joka esiintyy harjoitusaineistossa useiten annetun sanan yhteydess채, saavutetaan 90\% tunnistustarkkuus \citep{charniak1993}.

 On my철s mielenkiintoista huomata, ett채 edes ammattilaisten k채sin luokittelemat aineistot eiv채t saavuta t채ydellist채 tunnistamistarkkuutta: ihmisten sanaluokkien tunnistamistarkkuuden on arvioitu olevan noin 97\% \citep{manning2011}, mik채 vastaa edell채mainittua automaattisten tunnistajien huipputulosta.


\section{Sanaluokkien tunnistajan vaatimukset}

Jotta tunnistajaa voidaan k채ytt채채 laajan kielenprosessointij채rjestelm채n komponenttina, tulee sen toteuttaa seuraavat ominaisuudet ~\citep{cutting1992}: 

\begin{description}[labelindent=1cm]
 \item[Kest채vyys] Tunnistajan tulee kyet채 selviytym채채n kaikista tekstisy철tteen mahdollisista poikkeamista, kuten otsikoista, taulukoista sek채 tuntemattomista sanoista.
 \item[Tehokkuus] Voidakseen k채sitell채 laajoja tekstiaineistoja tunnistajan tulee toimia lineaarisessa ajassa. 
 \item[Tarkkuus] Tunnistajan tulee kyet채 ehdottamaan sanaluokka jokaista annettua sanaa kohden. My철s tunnistajan mahdollisen opettamisen tulisi onnistua mahdollisimman nopeasti.
 \item[Viritett채vyys] Tunnistajan tulee osata hy철dynt채채 erilaisia kielitieteellisi채 huomioita siten, ett채 tunnistajan tekemi채 virheit채 voidaan paikata m채채ritt채m채ll채 sopivia vihjeit채.
 \item[Uudelleenk채ytett채vyys] Tunnistajan tulee rakentua siten, ett채 sen kohdistaminen uudelle kielelle, aineistolle tai sanaluokkasetille on mahdollisimman vaivatonta.
\end{description}

\section{Harjoitusaineisto ja sanaluokkasetit}

TODO T채ss채 kappaleessa mainitaan yleisimm채t harjoitusaineistot ja sanaluokkasetit (Brown, Penn Treebank). Mahd. syyt채 t채sment채채, ett채 on kyse ohjatusta oppimisesta. Testiaineiston ja harjoitusaineiston erot; mit채 seuraa jos liian erilaiset? Ongelmaan vaikuttaa my철s tunnistettavien sanaluokkien m채채r채: mit채 enemm채n sanaluokkia, sit채 suurempi mahdollisuus monitulkintaisuuteen. Harjoitusaineiston koko. \DIFaddbegin \DIFadd{Ongelmallista on my철s tunnistamisessa k채ytett채vien sanaluokkien (engl. }\emph{\DIFadd{POS tagset}}\DIFadd{) valinta. Yleisi채 englannin kielen sanaluokkasettej채 ovat Brownin aineiston 87 sanaluokkaa \mbox{%DIFAUXCMD
\citep{francis1964}
}%DIFAUXCMD
, tai uudemman Penn Treebank-aineiston 48 sanaluokkaa \mbox{%DIFAUXCMD
\citep{marcus1993}
}%DIFAUXCMD
. My철s yleisi채, kielest채 riippumattomia sanaluokkasettej채 on kehitetty, joskin t채ll철in joudutaan v채ist채m채tt채 tinkim채채n tunnistamistarkkuudesta \mbox{%DIFAUXCMD
\citep{petrov2011}
}%DIFAUXCMD
.
}\DIFaddend 

\DIFaddbegin \DIFadd{Yleens채 puhutaan 8:sta tagista, NLP:ll채 eri vaatimukset: p채채temerkit yms.
}


\DIFaddend \chapter{Transformaatios채채nn철t}

TODO
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < 
%DIFDELCMD < %%%
\chapter{\DIFdel{Markovin piilomallit}}
%DIFAUXCMD
\addtocounter{chapter}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{TODO
}\DIFdelend \DIFaddbegin \DIFadd{+ yksinkertainen }\\
\DIFadd{+ vaatii v채h채n muistia vrt. tilastolliset menetelm채t }\\
\DIFadd{+ lopputuloksena saadaan lingvistisesti merkityksellist채 ja helposti tulkittavaa dataa --- s채채nt철j채 }\\
\DIFaddend - \DIFdelbegin \DIFdel{esimerkkikuva Markovin ketjusta
}\DIFdelend \DIFaddbegin \DIFadd{hitaampi opettaa }\\
\DIFaddend - \DIFdelbegin \DIFdel{markov-oletus
- markovin ketjut
- bigrammit/trigrammit
- miksi piilotettu?
}\DIFdelend \DIFaddbegin \DIFadd{huonompi tarkkuus
}\DIFaddend 

\DIFaddbegin \chapter{\DIFadd{Markovin piilomallit}}

\DIFaddend Markovin malli (mm. \citealp{rabiner1989}) kuvaa sellaista stokastista prosessia, \DIFdelbegin \DIFdel{jonka vallitseva }\DIFdelend \DIFaddbegin \DIFadd{joka toteuttaa ns. Markov-ominaisuuden: seuraava }\DIFaddend tila riippuu aina vain \DIFaddbegin \DIFadd{$N$:st채 }\DIFaddend edelt채\DIFdelbegin \DIFdel{vist}\DIFdelend \DIFaddbegin \DIFadd{v}\DIFaddend \DIFdelbegin \DIFdel{tiloista. Yksinkertaisimmillaan malli koostuu havaintoja kuvaavista tiloista, joille kullekin on }\DIFdelend \DIFaddbegin \DIFadd{st채 tilasta. Markov-ominaisuus on siis er채채nlainen riippumattomuusoletus, yksinkertaistaa stokastisen prosessin tilan estimointia rajoittamalla tilasiirtymien historian }\DIFaddend m채채r채\DIFdelbegin \DIFdel{tty tilasiirtymien }\DIFdelend \DIFaddbegin \DIFadd{채. $N$:nen asteen Markov-ominaisuuden toimiessa esimerkiksi }\DIFaddend todenn채k철\DIFdelbegin \DIFdel{isyydet}\DIFdelend \DIFaddbegin \DIFadd{isyys
}

\[\DIFadd{
P(x_k | x_1, \ldots, x_{k-1})
}\]

\DIFadd{voidaan laskea huomattavasti yksinkertaisemmin tarkastelemalla vain $N$:채채 edellist채 tilaa:
}

\[\DIFadd{
P(x_k | x_{k - N }, \ldots, x_{k-1})
}\]

\DIFadd{Markov-ominaisuudesta puhuttaessa on yleens채 kyse juuri ensimm채isen asteen Markov-ominaisuudesta, jolloin $N=1$}\DIFaddend . \DIFdelbegin \DIFdel{Usein prosessin tila ei kuitenkaan ole suoraan havaittavissa}\DIFdelend \DIFaddbegin \DIFadd{K채yt채nn철ss채 t채m채 tarkoittaa sit채}\DIFaddend , \DIFdelbegin \DIFdel{eli tila on piilotettu, joskin havainnosta riippuvainen ; }\DIFdelend \DIFaddbegin \DIFadd{ett채 tarkastellaan jotakin kahta per채kk채ist채 tilaa --- nykyist채 sek채 tulevaa. Markov-ominaisuutta voidaan kuitenkin laajentaa my철s korkeampiin asteisiin, jolloin my철s tarkasteltavien tilasarjojen pituudet kasvavat. Sanaluokkia tunnistaessa n채it채 tilasarjoja vastaavat n:n per채kk채isen sanaluokan sarjat, eli ns. n-grammit.   
}

\DIFadd{Yksinkertaisimmillaan Markovin mallia voidaan kuvata tilakoneena, joka koostuu havaittavia tapahtumia kuvaavista tiloista, sek채 tilasiirtym채matriisista, josta ilmenev채t todenn채k철isyydet siirty채 kustakin tilasta mihin tahansa muuhun tilaan. Kukin tila on siis itsen채inen ja muistiton.
}

\DIFadd{TODO Mahd. selitykset HMM:n viidest채 elementist채 \mbox{%DIFAUXCMD
\citep{rubiner1989}
}%DIFAUXCMD
.
}



\DIFadd{TODO: }\DIFaddend t채\DIFdelbegin \DIFdel{ll}\DIFdelend \DIFaddbegin \DIFadd{h채n esimerkkikuva Markovin ketjusta
}

\DIFadd{Markovin mallin hy}\DIFaddend \DIFdelbegin \DIFdel{in on kyse Markovin piilomallista. Sanaluokkien tunnistamisongelma voidaan kuvata kyseisen}\DIFdelend \DIFaddbegin \DIFadd{dyllisyytt}\DIFaddend  \DIFdelbegin \DIFdel{piilomallina: }\DIFdelend \DIFaddbegin \DIFadd{rajoittaa se, ett채 malli ei pysty itsess채채n mallintamaan prosesseja, joiden tilat eiv채t ole suoraan havaittavissa. Useimmissa mielenkiintoisissa tapauksissa prosessin tilat eiv채t kuitenkaan suoraan vastaa havaintoja, eli prosessin tila --- vaikkakin havainnosta riippuvainen --- on piilotettu: esimerkiksi sanaluokkien tunnistamisongelmassa }\DIFaddend havainto (sana) on tiedossa, tila (sanaluokka) on riippuvainen havainnosta, mutta tila itsess채채n ei ole tiedossa. \DIFaddbegin \DIFadd{T채ll철in Markovin malli tulee laajentaa Markovin piilomalliksi, jossa havainto on aina sit채 vastaavan tilan todenn채k철isyysfunktio.
}\DIFaddend 

\DIFaddbegin \DIFadd{TODO: t채h채n kuva Markovin piilomallista
}




\DIFaddend \section{L채ht철kohta}

Tunnistamisongelmassa siis haetaan annetulla lauseelle sit채 todenn채k철isimmin vastaavaa sanaluokkien sarjaa. Todenn채k철isyytt채 voidaan mallintaa funktiolla

\[
p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n)
\]

mik채 ilmaisee todenn채k철isyyden sille, ett채 jokin lause $ w_1 \ldots w_n $ esiintyy jonkin sanaluokkasarjan $ t_1 \ldots t_n $ yhteydess채. T채ll철in ratkaistavaksi j채채

\[
\argmax{t_1 \ldots t_n} p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n)
\]

eli sanaluokkasarja $ t_1 \ldots t_n $, jolla saadaan maksimiarvo edelt채v채st채 funktiosta. Mahdollisten sanaluokkasarjojen m채채r채 kuitenkin kasvaa eksponentiaalisesti sanojen ja sanaluokkien m채채r채n mukaan, jolloin maksimiarvon ratkaiseminen on ep채tehokasta.


\section{Tunnistusongelma Markovin piilomallina}

Markovin piilomallien avulla edell채mainittu funktio $ p $ voidaan kuvata muodossa

\[
p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n) = \underbrace{\prod_{i=1}^{n+1} q(t_i | t_{i-2}, t_{i-1})}_\text{Markovin ketju}\prod_{i=1}^{n}e(w_i | t_i)
\]

miss채 $t_0$ ja $t_{-1}$ ovat lauseen alkuun lis채ttyj채 alkusanaluokkia, ja $t_{n+1}$ on p채채temerkkisanaluokka. Mallin ensimm채inen parametri

\[
q(t_i | t_{i-2}, t_{i-1})
\]

laskee todenn채k철isyyden sanaluokalle $t_i$, kun kaksi edelt채v채채 sanaluokkaa ovat $t_{i-1}$ ja $t_{i-2}$. \DIFaddbegin \DIFadd{Parametri voidaan my철s mielt채채 todenn채k철isyyten채 trigrammille $t_{i-2}, t_{i-1}, t_i $. }\DIFaddend T채st채 \DIFdelbegin \DIFdel{trigrammista }\DIFdelend voidaan p채채tell채, ett채 kyseess채 on \DIFdelbegin \DIFdel{ns. toisen }\DIFdelend \DIFaddbegin \DIFadd{kolmannen }\DIFaddend asteen Markovin piilomalli. Mallin toinen parametri

\[
e(w_i | t\DIFdelbegin \DIFdel{_1}\DIFdelend \DIFaddbegin \DIFadd{_i}\DIFaddend )
\]

laskee todenn채k철isyyden sille, ett채 sana $w_i$ esiintyy sanaluokan $t_i$ yhteydess채.


\subsection{Parametrien estimointi}

Yksinkertaisimmillaan parametri $q(t_i|t_{i-2},t_{i-1})$ voidaan estimoida laskemalla

\[
q(t_3|t_1,t_2) = \frac{f(t_1,t_2,t_3)}{f(t_1,t_2)}
\]

miss채 funktio $f$ merkitsee annetun n-grammin lukum채채r채채 harjoitusaineistossa. \citet{brants2000} kuitenkin osoittaa, \DIFdelbegin \DIFdel{ettei }\DIFdelend \DIFaddbegin \DIFadd{ett채 datan harvuuden vuoksi }\DIFaddend t채llainen estimaatti \DIFaddbegin \DIFadd{ei }\DIFaddend ole k채ytt철kelpoinen\DIFdelbegin \DIFdel{, sill채 }\DIFdelend \DIFaddbegin \DIFadd{: }\DIFaddend laajassakaan harjoitusaineistossa ei ole tarpeeksi montaa kappaletta kutakin eri trigrammia. Lis채ksi osa trigrammeista $t_i,t_{i+1},t_{i+2}$ ovat v채ist채m채tt채 sellaisia, ett채 $f(t_i,t_{i+1},t_{i+2}) = 0$, jolloin koko sarja $t_1 \ldots t_n$ saa todenn채k철isyyden $0$. Luotettavampi tapa estimoida arvoa $q$ on hy철dynt채채 trigrammien lis채ksi my철s harjoitusaineistosta johdettujen uni- ja \DIFdelbegin \DIFdel{digrammien }\DIFdelend \DIFaddbegin \DIFadd{bigrammien }\DIFaddend suhteellisia frekvenssej채:

\begin{align*}
Unigrammi&: P(t_3) = \frac{f(t_3)}{N} \\
\DIFdelbegin \DIFdel{Digrammi}\DIFdelend \DIFaddbegin \DIFadd{Bigrammi}\DIFaddend &: P(t_3 | t_2) = \frac{f(t_2, t_3)}{f(t_2)} \\
Trigrammi&: P(t_3 | t_1, t_2) = \frac{f(t_1,t_2,t_3)}{f(t_1,t_2)}
\end{align*}

miss채 $N$ merkitsee harjoitusaineiston sanojen kokonaislukum채채r채채. Nyt funktion $q$ arvoa voidaan silottaa interpoloimalla edell채mainittuja n-grammeja:

\[
q(t_3 | t_1, t_2) = \lambda_1 P(t_3) + \lambda_2 P(t_3 | t_2) + \lambda_3 P(t_3 | t_1, t_2)
\]

miss채 $\lambda_1+\lambda_2+\lambda_3 = 1$ ja $\lambda_1,\lambda_2,\lambda_3 \geq 0$ (TODO muut silotusmenetelm채t, perustelu interpolaatiolle). Vastaavasti todenn채k철isyys $e$ voidaan estimoida vertaamalla sana-sanaluokka-yhdistelm채n frekvenssi채 pelk채n sanaluokan frekvenssiin:

\[
e(w_3|t_3) = \frac{f(w_3, t_3)}{f(t_3)}
\]

\subsection{Tuntemattomien sanojen k채sittely}

Edellinen todenn채k철isyyden $e$ estimaatti ei kuitenkaan ole luotettava, jos sana $w$ ei esiinny harjoitusaineistossa kertaakaan. T채ll철in $e(w|t)=0$ mill채 tahansa sanaluokalla $t$, ja samoin 
$p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n) = 0$, jos yksik채채n sanoista $w_1 \ldots w_n$ on tuntematon. Yksinkertaisin ratkaisu on m채채r채t채 tuntemattoman sanalle aina harjoitusaineiston yleisin sanaluokka, k채yt채nn철ss채 substantiivi. Joitain kieli채 --- kuten englantia --- tulkittaessa voidaan saavuttaa parempia tuloksia suffiksianalyysin \citep{samuelsson1993} avulla. T채ll철in tarkoituksena on hy철dynt채채 sit채 seikkaa, ett채 sanan p채채te on usein vahva indikaattori sen sanaluokasta. Lis채ksi \citet{toutanova2003} ovat esitt채neet, kuinka seuraavassa kappaleessa esitelt채vi채 log-lineaarisia malleja voidaan hy철dynt채채 tuntemattomien sanojen k채sittelyss채.


\subsection{Viterbin algoritmi}

T채ss채 kappaleessa kuvaillaan lyhyesti Viterbin algoritmia, jolla ratkaistaan tehokkaasti em. arvo $\argmax{t_1 \ldots t_n} p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n)$.

\section{Parannukset (tjsp)}

T채h채n kuvaukset Cyclic Dependency Network-menetelm채st채 \citep{toutanova2003}, mahd. ohjaamattomasta oppimisesta \citep{banko2004}. The trigram assumption is arguably quite strong, and linguistically naive. However, it leads to models that are very useful in
practice.


\chapter{Log-lineaariset mallit}

TODO



\chapter{Menetelmien vertailua/analyysia}


TODO T채ss채 kappaleessa esitell채채n tunnistimien eri toimintaymp채rist철t (esim. erilaiset kielet, aineistot, harjoitusaineiston saatavuus), ja pohditaan miten eri menetelm채t toimivat eri olosuhteissa; vastataan siis tutkimuskysymykseen (miten eri menetelm채t eroavat toisistaan, ja soveltuvatko jotkin menetelm채t toisia paremmin tietyille toimintaymp채rist철ille).

Toisaalta voisi olla mielekk채채mp채채 perustella menetelmien etuja jo aikaisemmissa kappaleissa, niiden esittelyiden yhteydess채. Menetelmien esitysj채rjestys on sellainen, ett채 my철hempi menetelm채 tavallaan vastaa aikaisemman menetelm채n puutteisiin.  Lis채ksi t채ss채 kappaleessa esitelt채vi채 johtop채채t철ksi채 voisi j채tt채채 yhteenveto-kappaleeseen; kokonaisen kappaleen verran johtop채채t철ksi채 ja merkityksellist채 analyysia vaikuttaa turhan kunnianhimoiselta tavoitteelta.  Harkitsen siis t채m채n kappaleen poistamista.


\chapter{Yhteenveto}

TODO Yhteenvedossa kerrataan ty철n p채채kohdat lyhyehk철sti johtop채채t철ksi채 tehden. Siin채 voi my철s esitt채채 pohdintoja siit채, mink채laisia tutkimuksia aiheesta voisi jatkossa tehd채. \DIFaddbegin \DIFadd{viittaa kirjallisuuskatsauksen tarkoitukseen ja kertoo ''p채채tulokset''.
}\DIFaddend 



\begin{thebibliography}{}

\bibitem[Banko \& Moore(2004)]{banko2004}
Banko, M. \& Moore, R. C. (2004). \textit{Part of speech tagging in context}. Proceedings of the 20th conference on Computational Linguistics, ACL, s. 556.

\bibitem[Brants(2000)]{brants2000}
Brants, T. 2000. \textit{TnT - A statistical part-of-speech tagger}. Proceedings of the 6th Applied NLP Conference (ANLP).

\bibitem[Brill(1992)]{brill1992}
Brill, E. 1992. \textit{A simple rule-based part of speech tagger}. Proceedings of the 3rd conference on Applied Computational Linguistics, ACL, Trento, Italy.

\bibitem[Brill(1995)]{brill1995}
Brill, E. 1995. \textit{Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging}. Computational Linguistics, 21(4), s.~543-565.

\bibitem[Charniak ym.(1993)]{charniak1993}
Charniak, E., Hendrickson, C., Jacobson, N., \& Perkowitz, M. 1993. \textit{Equations for part-of-speech tagging}. Proceedings of AAAI-93, s.~784--789.

\bibitem[Church(1988)]{church1988}
Church, K. 1988. \textit{A stochastic parts program and noun phrase parser for unrestricted text}. Proceedings of the 2nd conference on Applied Natural Language Processing, s.~136--143.

\bibitem[Cutting ym.(1992)]{cutting1992}
Cutting, D., Kupiec, J., Pedersen, J. \& Sibun, P. 1992. \textit{A Practical Part-of-Speech Tagger}. Proceedings of the 3rd conference on Applied Natural Language Processing, s.~133--140.

\bibitem[DeRose(1988)]{derose1988}
DeRose, S. J. 1988. \textit{Grammatical category disambiguation by statistical optimization}. Computational Linguistics, 14(1), s.~31--39.

\bibitem[Francis(1964)]{francis1964}
Francis, W. N. 1964. \textit{A standard sample of present-day English for the use with digital computers}. Report for the U.S Office of Education on Cooperative Research Project No. E-007.
Brown University, Providence RI.

\bibitem[Garside(1987)]{garside1987}
Garside, R. 1987. \textit{The CLAWS word-tagging system}. Teoksessa R. Garside, G. Leech \& G. Sampson (toim.) The Computational Analysis of English: A Corpus-based Approach. London: Logman, s.~30-41.

\bibitem[Heckerman ym.(2000)]{heckerman2000}
Heckerman, D., Chickering, D. M., Meek, C., Rounthwaite, R. \& Kadie, C. M. 2000. \textit{Dependency networks for inference, collaborative filtering and data visualization}.
Journal of Machine Learning Research, 1(1), s.~49-75.

\bibitem[Jaynes(1957)]{jaynes1957}
Jaynes, E. T. 1957. \textit{Information Theory and Statistical Mechanics}. Physical Review, 106, s.~620-630.

\bibitem[Manning(2011)]{manning2011}
Manning, C. D. 2011. \textit{Part-of-Speech Tagging from 97\% to 100\%: Is It Time for Some Linguistics?} Proceedings of the 12th international conference on Computational linguistics and intelligent text processing, 1, s.~171--189.

\DIFdelbegin %DIFDELCMD < \bibitem[Manning \& Sch체tze(1999)]{manning1999}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \bibitem[Manning \& Sch\"{u}tze(1999)]{manning1999}
\DIFaddend Manning, C. D. \& \DIFdelbegin \DIFdel{Sch}\DIFdelend \DIFaddbegin \DIFadd{Sch}\"{u}\DIFaddend tze, H. 1999. \textit{Foundations of statistical natural language processing}.
Cambridge, MA\DIFdelbegin \DIFdel{: }\DIFdelend \DIFaddbegin \DIFadd{. }\DIFaddend MIT Press

\bibitem[Marcus ym.(1993)]{marcus1993}
Marcus, M. P., Marcinkiewicz, M. \& Santorini, B. 1993. \textit{Building a large annotated corpus of English: the Penn treebank}. Computational Linguistics, 19(2), s.~313-330.

\bibitem[Merialdo(1994)]{merialdo1994}
Merialdo, B. 1994. \textit{Tagging English text with a probabilistic model}. Computational Linguistics, 20(2), s.~155-171.

\bibitem[Petrov ym.(2011)]{petrov2011}
Petrov, S., Das, D. \& McDonald, R. 2011. \textit{A universal part-of-speech tagset}. ArXiv:1104.2086.

\bibitem[''POS Tagging State of the Art''(2013)]{aclwiki2013}
\textit{POS Tagging State of the Art}. 2013. The Wiki of the Association for Computational Linguistics.
Haettu 28.10.2013, osoitteesta \url{aclweb.org/aclwiki/index.php?title=POS_Tagging_(State_of_the_art)}

\bibitem[Rabiner(1989)]{rabiner1989}
Rabiner, L. R. 1989. \textit{A tutorial on Hidden Markov Models and selected applications in speech recognition}. Proceedings of the IEEE, 77(2), s.~257-285.

\bibitem[Ratnaparkhi(1996)]{ratnaparkhi1996}
Ratnaparkhi, A. 1996. \textit{A maximum entropy model for part-of-speech tagging}. Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP), University of Pennsylvania.

\bibitem[Ratnaparkhi(1997)]{ratnaparkhi1997}
Ratnaparkhi, A. 1997. \textit{ A simple introduction to maximum entropy models for natural language processing}.
Technical Report 97-08, Institute for Research in Cognitive Science, University of Pennsylvania, 1997.

\bibitem[Samuelsson(1993)]{samuelsson1993}
Samuelsson, C. 1993. \textit{Morphological tagging based entirely on Bayesian inference}. Proceedings of the 9th Nordic Conference on Computational Linguistics NODALIDA-93.

\bibitem[Shen ym.(2007)]{shen2007}
Shen, L., Satta, G. \& Joshi, A. 2007. \textit{Guided learning for bidirectional sequence classification}. In: ACL 2007. (2007)

\bibitem[Spoustova ym.(2009)]{spoustova2009}
Spoustova, D.j., Hajic, J., Raab, J. \& Spousta, M. 2009. \textit{Semi-supervised training for the averaged perceptron POS tagger}. Proceedings of the 12th Conference of the
European Chapter of the ACL (EACL 2009), s.~763-711.

\bibitem[S첩gaard(2010)]{sogaard2010}
S첩gaard, A. 2010. \textit{Simple semi-supervised training of part-of-speech taggers}. Proceedings of the ACL 2010 Conference Short Papers, s.~205-208.

\bibitem[Toutanova ym.(2003)]{toutanova2003}
Toutanova, K., Klein, D., Manning, C.D. \& Singer, Y. 2003. \textit{Feature-rich part-of-speech tagging with a cyclic dependency network}. In: NAACL 3. (2003), s.~252-259

\bibitem[Tseng ym.(2005)]{tseng2005}
Tseng, H., Jurafsky, D. \& Manning, C. 2005. \textit{Morphological features help POS tagging of unknown words across language varities}. Proceedings of the 4th SIGHAN bakeoff.

\end{thebibliography}

\end{document}
