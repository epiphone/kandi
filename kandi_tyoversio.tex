% !TeX encoding = utf8
%
% [ Tiedostossa käytetty merkistö on utf8, vaihtoehtoisesti voisi olla esim.]
% [ ISO 8859-1 eli Latin 1. Ylläoleva rivi ]
% [ tarvitaan, jos käyttää MiKTeX-paketin mukana tulevaa TeXworks-editoria. ]
%
% TIETOTEKNIIKAN KANDIDAATINTUTKIELMA
%
% Yksinkertainen LaTeX2e-mallipohja kandidaatintutkielmalle.
% Käyttää Antti-Juhani Kaijanahon kirjoittamaa gradu3-dokumenttiluokkaa.
%
% Jos kirjoitat pro gradu -tutkielmaa, tee mallipohjaan seuraavat muutokset:
%  - Poista dokumenttiluokasta optio bachelor .
%  - Poista makro \type .
%  - Lisää suuntautumisvaihtoehto makrolla \studyline .
%  - Lisää tieto ohjaajasta makrolla \supervisor .

\documentclass[utf8,bachelor,manualbib]{gradu3}

\usepackage{palatino} % valitaan oletusfonttia hieman tyylikkäämpi fontti

\usepackage{graphicx} % tarvitaan vain, jos halutaan mukaan kuvia
\usepackage{amsmath}  % tarvitaan käytettäessä monimutkaisten matemaattisten kaavojen ja \eqref-kaavaviittauksen yhteydessä
\usepackage{url} % tarvitaan \url-komentoa varten
\usepackage{booktabs}

\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{eucal}
\usepackage{pbox}
\usepackage{comment}
\usepackage{float}
\restylefloat{table}

% Otetaan käyttöön author-date-järjestelmän mukaiset lähdeviittaukset:
\usepackage{natbib}
% Vaihdetaan kirjoittajan nimen ja vuosiluvun väliseksi erottimeksi
% välilyönti (oletuserottimena on pilkku):
%\bibpunct{(}{)}{;}{a}{}{,}

\newcommand{\argmax}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{max}}\;}

% HUOM! Tämän tulee olla viimeinen \usepackage koko dokumentissa!
\usepackage[bookmarksopen,bookmarksnumbered,linktocpage]{hyperref}
\setcounter{tocdepth}{2}
\begin{document}

\title{Sanaluokkien automaattisen tunnistamisen menetelmät}

\translatedtitle{Methods for automated part-of-speech tagging}

%\studyline{}
\avainsanat{kieliteknologia, luonnollisten kielten käsittely, sanaluokkien tunnistaminen, koneoppiminen}
\keywords{computational linguistics, natural language processing, part-of-speech tagging, machine learning}
\tiivistelma{Tiivistelmä on tyypillisesti 5-10 riviä pitkä esitys työn pääkohdista (tausta, tavoite, tulokset, johtopäätökset).
}
\abstract{Englanninkielinen versio tiivistelmästä.
}

\author{Aleksi Pekkala}
\contactinformation{\texttt{aleksi.v.a.pekkala@student.jyu.fi}}
% jos useita tekijöitä, anna useampi \author-komento
%\supervisor{Kirsi Valjus}
% jos useita ohjaajia, anna useampi \supervisor-komento
%\type{kandidaatintutkielma} % tämän makron oletus on "pro gradu -tutkielma" ja bachelor-optiolla kandidaatintutkielma

\maketitle
  
\mainmatter


\chapter{Johdanto}


Sanaluokkien automaattinen tunnistaminen (engl. \emph{part-of-speech tagging}) tarkoittaa sanojen sanaluokkien tunnistamista tekstiyhteyden perusteella.  Tunnistamisprosessissa tarkastellaan tekstiaineistoa, kuten

\[a\:black\:cat\:jumped\:on\:the\:table\]

jonka perusteella pyritään päättelemään se sanaluokkien sarja, joka todennäköisimmin vastaa kyseistä aineistoa; tässä tapauksessa tuloksena voisi olla esimerkiksi

\[Det\:Adj\:Noun\:Verb\:Prep\:Det\:Noun\]

Sanaluokkien tunnistaminen on laajuudeltaan rajallinen ongelma: sen tarkoituksena ei ole jäsentää kokonaisia lauserakenteita tai tulkita lauseiden merkitystä --- tarkastelun alla ovat vain yksittäisten sanojen leksikaaliset kategoriat. Sanaluokkien tunnistaminen on kuitenkin välttämätön ensimmäinen askel useimmissa luonnollisten kielten käsittelyprosesseissa, ja siten yksi aihealueen keskeisimmistä osaongelmista.

Rajallisen laajuutensa myötä sanaluokkien tunnistaminen on paljon helpommin lähestyttävä ongelma kuin kielen täydellinen ymmärtäminen, ja sen ratkaisemiseksi onkin kehitetty useita kohtuullisen luotettavia menetelmiä. Täysin ratkaistusta ongelmasta ei kuitenkaan voida puhua, sillä yksikään tunnettu menetelmä ei vielä saavuta täydellistä tunnistustarkkuutta.

Sanaluokkien tunnistajia käytetään monissa erilaisissa luonnollisiin kieliin liittyvissä sovelluksissa, ja tunnistajalle asetetut vaatimukset vaihtelevat sovelluksittain. Myös tunnistettavien aineistojen välillä on valtavasti poikkeamia, esim. kielten sekä tekstilajien osalta. Lisäksi havaitaan, että nykyisten tunnistusmenetelmien saavuttamat tunnistustarkkuudet liikkuvat kaikki suunnilleen samoissa lukemissa. Kun ilmiselvin valintakriteeri on näin poissuljettu, on tehokkaimman menetelmän valinta vaikeampaa. Tunnistusmenetelmien toimintaperiaatteiden vaihdellessa merkittävästi on kuitenkin väistämätöntä, että jotkin menetelmät soveltuvat toisia paremmin tiettyihin tunnistustehtäviin. Tässä tutkielmassa pyritäänkin selventämään sitä, millaisia eri ratkaisuja sanaluokkien tunnistusongelmaan on olemassa ja mitkä ovat niiden tärkeimmät erot. Menetelmien suhteelliset ominaisuudet johdetaan tarkastelemalla lähemmin kunkin menetelmän toimintaa sekä menetelmään liittyvää tutkimuskirjallisuutta. 

Tutkielma rakentuu seuraavasti: toisessa luvussa annetaan lyhyt johdanto sanaluokkien tunnistamiseen ja sen haasteisiin. Luvuissa 3-5 tarkastellaan kolmea erilaista tunnistusmenetelmää: transformaatiosääntöjä, Markovin piilomalleja sekä log-lineaarisia malleja. Luvuissa esitellään menetelmien keskeiset ominaisuudet, sekä pyritään hahmottamaan niiden suhteelliset vahvuudet ja heikkoudet. Lopuksi vielä kootaan yhteen menetelmistä kerätyt huomiot ja esitellään johtopäätökset.

TODO olisiko syytä esitellä lyhyesti valitut menetelmät tässä, ja/tai mainita jotain valintaperusteista tai esitysjärjestyksestä (kaksi ensimmäistä ovat tavallaan toistensa vastakohtia, ja kolmas menetelmä yhdistää piirteitä kummastakin aikaisemmasta menetelmästä. Samalla menetelmät ovat järjestetty yksinkertaisimmasta monimutkaisimpaan.).


\chapter{Sanaluokkien automaattinen tunnistaminen}

Sanaluokkien tunnistaminen on tärkeä ja käytännöllinen ongelma, joka kohdataan lähes kaikissa luonnollisten kielten käsittelyyn liittyvissä tehtävissä. Tällaisia tehtäviä ovat mm. puheentunnistus, konekääntäminen sekä semanttinen haku ja analyysi. Kyseisissä tehtävissä sanaluokkien tunnistaja toimii jonkin laajemman prosessointiketjun alkupäässä, koko prosessille välttämättömänä esikäsittelijänä, joka mahdollistaa syötteen jatkokäsittelyn korkeammalla tasolla. Jatkokäsittelyn tyypillisin seuraava vaihe on tekstin jäsentäminen eli lauserakenteiden tunnistaminen. Oikeiden lauserakenteiden tunnistamisen kannalta on oleellista, että lauseiden sanaluokat on tunnistettu mahdollisimman virheettömästi: yksikin virheellinen sanaluokka voi tehdä oikean lauserakenteen tunnistamisesta mahdotonta, ja siten vääristää lauseen tulkittua merkitystä.


\section{Miksi sanaluokkien tunnistaminen on ongelmallista?}

Sanaluokkien tunnistaminen voi intuitiivisesti tuntua helpolta, mutta tehtävän automaatiota hankaloittavat kaksi oleellista ongelmaa: sanojen monitulkintaisuus sekä tuntemattomat sanat. Esimerkiksi lauseissa
\[Time\: flies\: like\: an\: arrow.\]
\[Fruit\: flies\: like\: a\: banana.\]
sana \textit{flies} esiintyy ensin verbinä ja sitten substantiivina. Sanan \textit{time} ilmeisin sanaluokka on substantiivi, mutta se voidaan mieltää myös imperatiiviverbinä, jolloin lauseen merkitys muuttuu täysin. Itse asiassa kummatkin esimerkkilauseet voidaan tulkita kymmenin eri tavoin, joista ilmeisimmän tulkinnan valitseminen automaattisesti on haastavaa. Lisäksi, vaikka tosielämässä tulkittavat lauseet ovat harvoin yhtä ongelmallisia kuin edellämainitut lingvistiset esimerkkilauseet, on monitulkintaisuus hyvin yleistä: arviolta 40\% englanninkielisen proosan sanastosta voidaan luokitella useampaan kuin yhteen sanaluokkaan \citep{derose1988}. 

Jatkokäsittelyn kannalta automaattisen tunnistajan oleellisin tehtävä onkin valita kaikista mahdollisista sanaluokista se, joka tuottaa luontevimman tulkinnan. Tällaisen yksikäsitteistämisen mahdollistavat luonnollisten kielten sisäänrakennetut rajoitteet, jotka voidaan jakaa lokaaleihin sekä kontekstuaalisiin vihjeisiin: lokaaleista vihjeistä ilmeisin on itse sana (''sana \textit{can} on on todennäköisemmin modaaliverbi kuin substantiivi''), mutta päätelmiä voidaan tehdä myös mm. sanan prefiksin, suffiksin tai kirjainten koon perusteella. Kontekstuaalisia vihjeitä ovat kaikki lauseen muut sanat sanaluokkineen: esimerkiksi sana \textit{fly} on todennäköisimmin substantiivi, jos edeltävä sana on artikkeli.

On tärkeää huomata, ettei sanaluokkien tunnistaminen itsessään ole ratkaisu kieliopilliseen monitulkintaisuuteen: monitulkintaisuudella on useita tasoja, joista osaa käsitellään vielä prosessointiketjun myöhemmissä vaiheissa. Esimerkiksi syntaktinen, tai rakenteellinen monitulkintaisuus on ongelma, joka on huomattavasti helpompi ratkaista lauseiden jäsennyksen yhteydessä. Sanaluokkien tunnistamista ei myöskään tule sekoittaa semanttiseen yksikäsitteistämiseen, eli sanan merkityksen selvittämiseen: esimerkiksi sana \textit{mouse} on semanttisesti monitulkintainen, vaikka sen sanaluokka tunnettaisiinkin. Sanaluokkien tunnistamisen rooli on pikemminkin rajata mahdollisten tulkintojen määrää prosessointiketjun alkupäässä, jotta myöhemmissä vaiheissa vältytään turhalta työltä.

Monitulkintaisuuden lisäksi toinen merkittävä ongelma on tuntemattomien, eli harjoitusaineistosta puuttuvien sanojen käsitteleminen. Englannin kielessä yleisiä tuntemattomia sanoja ovat erisnimet sekä puhekieliset, vieraskieliset ja muut harvinaiset ilmaisut. Tällaisia sanoja kohdataan usein, ja koska niitä koskevaa tilastollista informaatiota tai sääntöjä ei tunneta, joudutaan turvautumaan jonkinlaiseen poikkeuskäsittelyyn. Useat tunnistajat hyödyntävät tuntemattomien sanojen kohdalla kieliopillisia ominaisuuksia: yksinkertainen menetelmä on määrätä sanalle se sanaluokka, joihin tuntemattomien sanojen on havaittu todennäköisimmin kuuluvan, eli yleensä substantiivi. Parempia tuloksia on saavutettu määrittämällä tuntemattoman sanan sanaluokka sen päätteen perusteella; esim. englannin kielen \emph{able}-päätteiset sanat ovat hyvin todennäköisesti adjektiiveja \citep{samuelsson1993}. Menetelmä ei kuitenkaan sovellu kaikille kielille: esim. \citet{tseng2005} osoittavat, että kiinan kielessä esiintyy huomattavan suuri määrä yleisiä affikseja, poiketen englannin ja saksan kielistä, joissa affiksit ovat vahva indikaattori sanan sanaluokasta.


\section{Automaattisten tunnistajien suorituskyky}

Kuten mainittua, nykyisten automaattisten sanaluokkien tunnistajien tunnistustarkkuus --- englanninkielistä kirjakieltä analysoitaessa --- on hieman yli 97\%  (mm. \citealp{toutanova2003}, \citealp{shen2007}, \citealp{spoustova2009}). \citet{manning2011} kuitenkin osoittaa, että kyseistä tulosta ei ole syytä tulkita liian optimistisesti: esimerkiksi lukuisat välimerkit ja muut yksikäsitteiset elementit vääristävät evaluaatiotuloksia. Lisäksi useissa tekstilajeissa, kuten uutisiartikkeleissa, lauseiden keskipituus on yli 20 sanaa, jolloin edellämainitullakin tunnistustarkkuudella jokaisessa lauseessa on keskimäärin ainakin yksi virhe \citep{manning1999}. Artikkelissa huomautetaankin, että realistisempaa olisi tarkastella automaattisten tunnistajien kykyä tunnistaa kokonaiset lauseet oikein, sillä pienikin virhe lauseessa voi vahingoittaa tunnistajan hyödyllisyyttä myöhempien prosessointivaiheiden kannalta; tällä saralla tunnistajat saavuttavat noin 55-57\% tarkkuuden, mikä on huomattavasti vaatimattomampi tulos.

Tarkkuustuloksia arvioidessa tulee myös ottaa huomioon varsin korkea lähtötaso: jo yksinkertaisimmalla metodilla, eli valitsemalla kullekin sanalle se sanaluokka, joka esiintyy harjoitusaineistossa useiten annetun sanan yhteydessä, saavutetaan 90\% tunnistustarkkuus \citep{charniak1993}.

On myös mielenkiintoista huomata, että edes ammattilaisten käsin luokittelemat aineistot eivät saavuta täydellistä tunnistamistarkkuutta: ihmisten sanaluokkien tunnistamistarkkuuden on arvioitu olevan noin 97\% \citep{manning2011}, mikä vastaa edellämainittua automaattisten tunnistajien huipputulosta.


\section{Sanaluokkien tunnistajan vaatimukset}

Jotta tunnistajaa voidaan käyttää laajan kielenprosessointijärjestelmän komponenttina, tulee sen toteuttaa seuraavat ominaisuudet ~\citep{cutting1992}: 

\begin{description}[labelindent=1cm]
 \item[Kestävyys] Tunnistajan tulee kyetä selviytymään kaikista tekstisyötteen mahdollisista poikkeamista, kuten otsikoista, taulukoista sekä tuntemattomista sanoista.
 \item[Tehokkuus] Voidakseen käsitellä laajoja tekstiaineistoja tunnistajan tulee toimia lineaarisessa ajassa. Myös tunnistajan mahdollisen opettamisen tulisi onnistua kohtuullisen nopeasti.
 \item[Tarkkuus] Tunnistajan tulee kyetä ehdottamaan sanaluokka jokaista annettua sanaa kohden.
 \item[Viritettävyys] Tunnistajan tulee osata hyödyntää erilaisia kielitieteellisiä huomioita siten, että tunnistajan tekemiä virheitä voidaan paikata määrittämällä sopivia vihjeitä.
 \item[Uudelleenkäytettävyys] Tunnistajan tulee rakentua siten, että sen kohdistaminen uudelle kielelle, aineistolle tai sanaluokkasetille on mahdollisimman vaivatonta.
\end{description}

\section{Harjoitusaineisto ja sanaluokkasetit}

Sanaluokkien tunnistaminen on luonteeltaan sarjanluokitteluongelma, joka taas on yksi koneoppimisen (tarkemmin hahmontunnistuksen) aliongelmatyypeistä. Tämän seurauksena nykyiset sanaluokkien tunnistusmenetelmät perustuvat usein ohjattuun oppimiseen, eli tunnistimet tulee ''opettaa'' jonkinlaisella harjoitusaineistolla ennen käyttöä. Sanaluokkien tunnistimille syötettävä harjoitusdata koostuu suurista tekstiaineistoista (engl. \textit{corpus}), joissa jokaisen sanan yhteyteen on merkattu oikea sanaluokka. Nykyisin ehkä yleisimmin käytetty englanninkielinen harjoitusaineisto on ns. Penn Treebank-aineisto \citep{marcus1993}, joka sisältää noin viiden miljoonan sanan edestä uutisartikkeleita, kaunokirjallisuutta, tieteellisiä julkaisuja ym. tekstilajeja.

TODO harjoitusaineiston merkitys tunnistustuloksille.

Tunnistusongelmaan on olemassa myös ohjaamattomaan oppimiseen perustuvia ratkaisuja, jotka eivät vaadi valmiiksi luokiteltua harjoitusaineistoa. Toisaalta tällaiset menetelmät ovat väistämättä alttiimpia virheille kuin vastaavat ohjatun oppimisen menetelmät. Joissain tapauksissa --- esimerkiksi harvinaisia kieliä analysoitaessa --- luokiteltua harjoitusaineistoa ei kuitenkaan ole saatavilla, jolloin ohjaamaton oppiminen on ainoa vaihtoehto.

Tunnistamisessa käytetyt sanaluokat määräytyvät yleensä harjoitusaineiston mukaan: esimerkiksi Penn Treebank-aineiston käyttämä sanaluokkasetti koostuu 48 sanaluokasta, joista 12 ovat välimerkkejä. On tärkeää huomata, että käytettävän sanaluokkasetin laajuus vaikuttaa suoraan tunnistustarkkuuteen: mitä enemmän sanaluokkia, sitä suurempi mahdollisuus monitulkintaisuuteen. Toisaalta sanaluokkien tunnistamisen tuottama lingvistinen informaatio on sitä arvokkaampaa, mitä tarkempi jaottelu eri sanaluokkien välillä on. \citep{marcus1993}

TODO esimerkkipätkä harjoitusaineistosta.

% Tagset-taulukko tällä hetkellä piilotettu
\begin{comment}
{\renewcommand{\arraystretch}{0.8}
\begin{table}[H]\footnotesize
  \caption{Penn Treebank-sanaluokkasetti \citep{marcus1993}}
  \begin{tabular}{rllrll}
1. & CC & Coordinating conjunction & 25. & TO & to \\
2. & CD & Cardinal number & 26. & UH & Interjection \\
3. & DT & Determiner & 27. & VB & Verb, base form \\
4. & EX & Existential there & 28. & VBD & Verb, past tense \\
5. & FW & Foreign word & 29. & VBG & Verb, gerund/present \\
6. & IN & \pbox{20cm}{Preposition/subordinating \\ participle conjunction} & 30. & VBN & Verb, past participle \\
7. & JJ & Adjective & 31. & VBP & Verb, non-3rd ps. sing. present \\
8. & JJR & Adjective, comparative & 32. & VBZ & Verb, 3rd ps. sing. present \\
9. & JJS & Adjective, superlative & 33. & WDT & wh-determiner \\
10. & LS & List item marker & 34. & WP & wh-pronoun \\
11. & MD & Modal & 35. & WP\$ & Possessive wh-pronoun \\
12. & NN & Noun, singular or mass & 36. & WRB & wh-adverb \\
13. & NNS & Noun, plural & 37. & \# & Pound sign \\
14. & NNP & Proper noun, singular & 38. & \$ & Dollar sign \\
15. & NNPS & Proper noun, plural  & 39. & . & Sentence-final punctuation \\
16. & PDT & Predeterminer & 40. & , & Comma \\
17. & POS & Possessive ending & 41. & : & Colon, semi-colon \\
18. & PRP & Personal pronoun & 42. & ( & Left bracket character \\
19. & PP\$  &Possessive pronoun & 43. & ) & Right bracket character \\
20. & RB & Adverb & 44. & " & Straight double quote \\
21. & RBR & Adverb, comparative & 45. & ' & Left open single quote \\
22. & RBS & Adverb, superlative & 46. & " & Left open double quote \\
23. & RP & Particle & 47. & ' & Right close single quote \\
24. & SYM & Symbol (mathematical or scientific)& 48. & " & Right close double quote

  \end{tabular}
  \label{table:penntagset}
\end{table}
\end{comment}


\chapter{Transformaatiosäännöt}

Ensimmäiset automaattiset sanaluokkatunnistimet (mm. \citealp{greene1971}) olivat lähtöisin kielitieteen piiristä, ja ne perustuivat pitkälti käsin laadittuihin kieliopillisiin sääntöihin. Tällainen sääntöpohjainen menetelmä toimii seuraavasti: ensin kunkin sanan mahdolliset sanaluokat haetaan sanakirjasta tai vastaavasta tietolähteestä. Seuraavaksi monitulkintaisten sanojen kohdalla sovelletaan valmiita kielioppisääntöjä sanaluokkien poissulkemiseen, kunnes jäljelle on enään yksi sanaluokka. Kielioppisäännöt voivat hyödyntää sekä lokaaleja että kontekstuaalisia vihjeitä; tyypillisiä sääntöjä ovat esimerkiksi
%\textit{hylkää sanaluokka $x$ jos sanalla on iso alkukirjain} (lokaali vihje) tai \textit{hylkää sanaluokka $x$, jos edeltävä sanaluokka on $y$} (kontekstuaalinen vihje).

\begin{enumerate}
\item \textit{hylkää sanaluokka $x$ jos sanalla on iso alkukirjain} (lokaali vihje), sekä
\item \textit{hylkää sanaluokka $x$, jos edeltävä sanaluokka on $y$} (kontekstuaalinen vihje).
\end{enumerate}

Tällaisen lähestymistavan ilmeisin heikkous on vaaditun manuaalisen työn määrä: erilaisille aineistoille tulee aina luoda uusi, aineiston kielelle ja tyylille spesifi sääntökokoelma. Huomattavan työpanoksen lisäksi sääntöpohjainen menetelmä vaatii myös ymmärryksen tulkittavan aineiston kieliopillisista erikoispiirteistä, jotta luodut säännöt tuottavat toivotun tuloksen. Puhtaasti sääntöpohjaisilla menetelmillä voidaan saavuttaa --- sääntöjen määrästä riippuen --- korkeita tarkkuustuloksia, mutta kyseiset tulokset eivät ole siirrettävissä erilaisille aineistoille ilman mittavia muutostöitä.

Sääntöpohjaisten menetelmien puutteiden vuoksi useimmat nykyiset sanaluokkien tunnistajat perustuvat tilastollisiin menetelmiin: sanaluokkia koskeva tilastollinen informaatio voidaan poimia harjoitusaineistosta automaattisesti, siinä missä sääntöjen laatiminen vaatii lingvististä asiantuntemusta ja manuaalista työtä. Sääntöpohjaisilla menetelmillä on kuitenkin joitakin etuja tilastollisiin menetelmiin verrattuna: ensinnäkin kielioppisääntöjen tallentaminen vaatii huomattavasti vähemmän tallennustilaa kuin vastaava tilastollinen informaatio. Tilastollista informaatiota on myös hankalampi tulkita ja käsitellä kuin yksinkertaisia kielioppisääntöjä, jonka myötä tunnistusvirheiden tunnistaminen ja korjaaminen on helpompaa kielioppisääntöjä käytettäessä. \citep{brill1992}

\citet{brill1992} huomauttaakin, että tilastolliset tunnistajat saavuttavat korkean tunnistamistarkkuuden kiinnittämättä varsinaisesti huomiota aineiston taustalla olevaan kieliopilliseen rakenteeseen. Hän laskee tilastollisten menetelmien puutteeksi sen, että ne poimivat aineistosta lingvistisen informaation sijaan vain suuren määrän vaikeselkoisia tilastoja.

\section{Brillin sääntöpohjainen sanaluokkatunnistin}

\citet{brill1992} esittää artikkelissaan vaihtoehtoisen lähestymistavan, joka pohjautuu varhaisimpien tunnistusmenetelmien tavoin kieliopillisiin sääntöihin. Aikaisemmista sääntöpohjaisista menetelmistä poiketen sääntöjä ei kuitenkaan syötetä manuaalisesti, vaan tunnistin oppii ne automaattisesti oikeilla sanaluokilla merkitystä harjoitusaineistosta. Menetelmän kantava idea on (1) aloittaa jostakin yksinkertaisesta ratkaisusta, (2) tunnistaa tehdyt virheet ja (3) inkrementaalisesti soveltaa virheitä korjaavia transformaatiosääntöjä, kunnes ne eivät enään paranna kokonaistarkkuutta.

\subsection{Toiminta}

Brillin tunnistinta alustettaessa harjoitusaineisto jaetaan kahteen osaan, joista pienempää käytetään niinsanottuna sääntöaineistona (engl. \textit{patch corpus}) ja suurempaa varsinaisena harjoitusaineistona. Tunnistimen alustaminen alkaa siten, että sääntöaineiston kukin sana luokitellaan ensin sillä sanaluokalla, joka useimmiten esiintyy sanan yhteydessä harjoitusaineistossa. Tuntemattomien sanojen kohdalla sanaluokka määräytyy sanan kolmen viimeisen kirjaimen mukaan: esimerkiksi kaikki \textit{ous}-päätteiset tuntemattomat sanat luokitellaan adjektiiveiksi, koska harjoitusaineiston \textit{ous}-päätteiset sanat ovat useimmiten adjektiiveja. Lisäksi kaikki isolla alkukirjaimella alkavat tuntemattomat sanat luokitellaan erisnimiksi. Tämän yksinkertaisen menetelmän tarkkuus on noin 92\%. \citep{brill1992}

Seuraavaksi verrataan edellämainitulla menetelmällä tunnistettuja sanaluokkia sääntöaineiston oikeisiin sanaluokkiin. Vertailun tuloksena saadaan lista virheistä muodossa $<tag_a, tag_b, number>$, josta ilmenee montako kertaa jokin sana tunnistettiin luokkaan $tag_a$, kun oikea sanaluokka olisi ollut $tag_b$. Nyt käyttämällä valmiita sääntörunkoja (taulukkoviittaus) voidaan laskennallisesti selvittää se transformaatiosääntö, joka laskee virheprosenttia eniten. Kunkin virhe-sääntörunko-parin muodostamaa sääntöä siis sovelletaan vuorostaan sääntöaineistoon, ja säännön arvo lasketaan vähentämällä korjattujen virheiden määrästä mahdollisesti aiheutettujen uusien virheiden lukumäärä. \citep{brill1992}

Kun arvokkain transformaatiosääntö on löydetty, sääntö laitetaan muistiin ja sääntöaineistoon tehdään löydetyn säännön mukaiset muutokset. Prosessia jatketaan keräämällä taas lista sääntöaineiston tunnistusvirheistä, ja etsimällä uusi paras transformaatiosääntö. Tätä toistetaan, kunnes ei enään löydetä sellaista sääntöä, joka tuottaisi enemmän korjauksia kuin aiheuttaisi uusia virheitä. Tällöin alustamisprosessi on valmis, ja tuloksena saatuja transformaatiosääntöjä voidaan soveltaa uuden aineston tunnistamiseen seuraavasti: ensin aineisto luokitellaan edellämainitulla yksinkertaisella menetelmällä. Tämän jälkeen aineistoon sovelletaan kutakin alustusvaiheessa löydettyä transformaatiosääntöä, jolloin virheprosentti laskee.

\subsection{Leksikalisointi}

\subsection{Tuntemattomien sanojen käsittely}

\subsection{FastTBL}
sääntöjen määrän vaikutus

\section{Arviota}
1. Sääntöjen kanssa ei tarvitse olla tarkkana. Sääntöjä ei tarvita paljon. - can capture more context than Markov models
2. Koska säännöt ovat niin yksinkertaisia, onko mahdollista parantaa tarkkuustuloksia tekemällä käsin uusia sääntöjä, heuristisesti? (se saksalaisten artikkeli)
3. ei tilastollista informaatiota, mitä voidaan joskus tarvita. (ainakaan ilman muutoksia).
4. Hidas. yksi artikkeli? (edellisessä kappaleessa jo käsitelty, ei tarvitse alustaa jos aineisto on samanlaista)
5. tarkkuus? \citet{brill1995} myös väittää, että jos aineistopohjaisessa luonnollisten kielten käsittelyssä halutaan saavuttaa edistysaskeleita, on pyrittävä ymmärtämään itse kieltä tilastollisten rinnakkaisilmiöiden sijaan. \citet{manning2011} vain kuudesosa ongelmista ratkaistu, oliko Brill oikeassa?


\chapter{Markovin piilomallit}

Edellisestä sääntöpohjaisesta menetelmästä poiketen useimmat nykyiset sanaluokkien tunnistajat perustuvat tilastollisiin menetelmiin. Tilastollisissa menetelmissä sanaluokkien tunnistaminen mielletään lingvistisen lähestymistavan sijaan koneoppimisongelmaksi, tai tarkemmin sarjanluokitteluongelmaksi. Sarjanluokitteluongelmassa tavoitteena on oppia funktio $f: \mathcal{X} \to \mathcal{Y}$, joka luokittelee kunkin syötteen $x$ johonkin luokkaan $y$. Todennäköisyyslaskennan kautta funktio $f$ voidaan määritellä muodossa

\begin{align}
f(x) = \argmax{y \in \mathcal{Y}} P(y|x)
\end{align}

missä todennäköisyyttä $P(y|x)$ estimoidaan harjoitusaineiston perusteella.

Tilastolliset mallit voidaan vuorostaan jakaa diskriminatiivisiin ja generatiivisiin malleihin. Diskriminatiiviset mallit (esim. log-lineaariset mallit) käsittelevät suoraan todennäköisyyttä $P(y|x)$, eli ne eivät ota kantaa syötteeseen $x$. Generatiiviset mallit (esim. Markovin piilomallit) puolestaan käsittelevät koko yhteisjakaumaa $P(x,y)$, josta todennäköisyys $P(y|x)$ johdetaan Bayesin säännön avulla. Diskriminatiiviset mallit ovat siten generatiivisia malleja rajoittuneempia, mutta sarjanluokitteluongelman kannalta mallin rajoitteilla ei ole väliä. Intuition mukaan generatiivinen malli on diskriminatiivista mallia tehottomampi, sillä yhteisjakauman mallintaminen on laskennallisesti vaativampaa kuin ehdollisen jakauman. \citet{ng2002} kuitenkin osoittavat, ettei tämä välttämättä aina pidä paikkaansa: sanaluokkien tunnistamiseen onkin olemassa kumpaankin malliin perustuvia tehokkaita ratkaisuja.

\section{Markovin malli}

Markovin malli (mm. \citealp{rabiner1989}) kuvaa sellaista stokastista prosessia, joka toteuttaa ns. Markov-ominaisuuden: seuraava tila riippuu aina vain $N$:stä edeltävästä tilasta. Markov-ominaisuus on siis eräänlainen riippumattomuusoletus, joka yksinkertaistaa stokastisen prosessin tilan estimointia rajoittamalla tilasiirtymien historian määrää. $N$:nen asteen Markov-ominaisuuden toimiessa esimerkiksi todennäköisyys

\begin{align}
P(x_k | x_1, \ldots, x_{k-1})
\end{align}

voidaan laskea huomattavasti yksinkertaisemmin tarkastelemalla vain $N$:ää edellistä tilaa:

\begin{align}
P(x_k | x_{k - N }, \ldots, x_{k-1})
\end{align}

Markov-ominaisuudesta puhuttaessa on yleensä kyse juuri ensimmäisen asteen Markov-ominaisuudesta, jolloin $N=1$. Käytännössä tämä tarkoittaa sitä, että tarkastellaan jotakin kahta peräkkäistä tilaa --- nykyistä sekä tulevaa. Markov-ominaisuutta voidaan kuitenkin laajentaa myös korkeampiin asteisiin, jolloin myös tarkasteltavien tilasarjojen pituudet kasvavat. Sanaluokkia tunnistaessa näitä tilasarjoja vastaavat n:n peräkkäisen sanaluokan sarjat, eli ns. n-grammit.   

TODO: Asteen valinnan merkitys.

Yksinkertaisimmillaan Markovin mallia voidaan kuvata tilakoneena, joka koostuu havaittavia tapahtumia kuvaavista tiloista, sekä tilasiirtymämatriisista, josta ilmenevät todennäköisyydet siirtyä kustakin tilasta mihin tahansa muuhun tilaan. Kukin tila on siis itsenäinen ja muistiton.

TODO Mahd. selitykset HMM:n viidestä elementistä \citep{rabiner1989}, esimerkkikuva Markovin ketjusta.


\subsection{Markovin piilomalli}

Markovin mallin hyödyllisyyttä rajoittaa se, että malli ei pysty itsessään mallintamaan prosesseja, joiden tilat eivät ole suoraan havaittavissa. Useimmissa mielenkiintoisissa tapauksissa prosessin tilat eivät kuitenkaan suoraan vastaa havaintoja, eli prosessin tila --- vaikkakin havainnosta riippuvainen --- on piilotettu: esimerkiksi sanaluokkien tunnistamisongelmassa havainto (sana) on tiedossa, tila (sanaluokka) on riippuvainen havainnosta, mutta tila itsessään ei ole tiedossa. Tällöin Markovin malli tulee laajentaa Markovin piilomalliksi, jossa havainto on aina sitä vastaavan tilan todennäköisyysfunktio.

TODO: tähän kuva Markovin piilomallista


\section{Lähtökohta}

Tunnistamisongelmassa siis haetaan annetulla lauseelle sitä todennäköisimmin vastaavaa sanaluokkien sarjaa. Todennäköisyyttä voidaan mallintaa yhteisjakaumalla

\begin{align}
p(w_1, w_2, \ldots, w_n,\: t_1, t_2, \ldots, t_n)
\label{generativemodel}
\end{align}

mikä ilmaisee todennäköisyyden sille, että jokin lause $ w_1 \ldots w_n $ esiintyy jonkin sanaluokkasarjan $ t_1 \ldots t_n $ yhteydessä. Tällöin ratkaistavaksi jää

\begin{align}
\argmax{t_1 \ldots t_n} p(w_1, w_2, \ldots, w_n,\: t_1, t_2, \ldots, t_n)
\end{align}

eli sanaluokkasarja $ t_1 \ldots t_n $, jolla saadaan maksimiarvo edeltävästä funktiosta. Mahdollisten sanaluokkasarjojen määrä kuitenkin kasvaa eksponentiaalisesti sanojen ja sanaluokkien määrän mukaan, jolloin maksimiarvon ratkaiseminen naiivisti on epätehokasta.


\section{Tunnistusongelma Markovin piilomallina}

Markovin piilomallit hyödyntävät sitä yhteisjakauman laskusääntöä $P(x,y) = P(y)P(x|y)$. Tällöin edellämainittu funktio $ p $ \eqref{generativemodel} voidaan kuvata muodossa (TODO: parempi selitys siitä miten parametrit vastaavat yhteisjakauman osia, e = P(x|y) ja q = P(y)


\begin{align}
& \hphantom{= } p(w_1, w_2, \ldots, w_n,\: t_1, t_2, \ldots, t_n) \\
& = p(t_1, t_2, \ldots, t_n)\:p(w_1, w_2, \ldots, w_n|t_1, t_2, \ldots, t_n) \\
& = \prod_{i=1}^{n+1} q(t_i | t_{i-2}, t_{i-1}) \prod_{i=1}^{n}e(w_i | t_i)
\end{align}

missä $t_0$ ja $t_{-1}$ ovat lauseen alkuun lisättyjä alkusanaluokkia, ja $t_{n+1}$ on päätemerkkisanaluokka. Mallin ensimmäinen parametri

\begin{align}
q(t_i | t_{i-2}, t_{i-1})
\end{align}

laskee todennäköisyyden sanaluokalle $t_i$, kun kaksi edeltävää sanaluokkaa ovat $t_{i-1}$ ja $t_{i-2}$. Parametri voidaan myös mieltää todennäköisyytenä trigrammille $t_{i-2}, t_{i-1}, t_i $. Tästä huomataan, että kyseessä on toisen asteen Markovin piilomalli. Mallin toinen parametri

\begin{align}
e(w_i | t_i)
\end{align}

laskee todennäköisyyden sille, että sana $w_i$ esiintyy sanaluokan $t_i$ yhteydessä.


\subsection{Parametrien estimointi}

Yksinkertaisimmillaan parametri $q(t_i|t_{i-2},t_{i-1})$ voidaan estimoida laskemalla

\begin{align}
q(t_i|t_{i-2},t_{i-1}) = \frac{f(t_{i-2},t_{i-1},t_i)}{f(t_{i-1},t_{i-1})}
\end{align}

missä funktio $f$ merkitsee annetun n-grammin lukumäärää harjoitusaineistossa. \citet{brants2000} kuitenkin osoittaa, että datan harvuuden vuoksi tällainen estimaatti ei ole käyttökelpoinen: laajassakaan harjoitusaineistossa ei ole tarpeeksi montaa kappaletta kutakin eri trigrammia. Lisäksi osa trigrammeista $t_{i-2},t_{i-1},t_i$ ovat väistämättä sellaisia, että $f(t_{i-2},t_{i-1},t_i) = 0$, jolloin koko sarja $t_1 \ldots t_n$ saa todennäköisyyden $0$. Luotettavampi tapa estimoida arvoa $q$ on hyödyntää trigrammien lisäksi myös harjoitusaineistosta johdettujen uni- ja bigrammien suhteellisia frekvenssejä:

\begin{align}
Unigrammi&: P(t_i) = \frac{f(t_i)}{N} \\
Bigrammi&: P(t_i | t_{i-1}) = \frac{f(t_{i-1}, t_i)}{f(t_{i-1})} \\
Trigrammi&: P(t_i | t_{i-2}, t_{i-1}) = \frac{f(t_{i-2},t_{i-1},t_i)}{f(t_{i-2},t_{i-1})}
\end{align}

missä $N$ merkitsee harjoitusaineiston sanojen kokonaislukumäärää. Nyt funktion $q$ arvoa voidaan silottaa interpoloimalla edellämainittuja n-grammeja:

\begin{align}
q(t_i | t_{i-2}, t_{i-1}) = \lambda_1 P(t_i) + \lambda_2 P(t_i | t_{i-1}) + \lambda_3 P(t_i | t_{i-2}, t_{i-1})
\end{align}

missä $\lambda_1+\lambda_2+\lambda_3 = 1$ ja $\lambda_1,\lambda_2,\lambda_3 \geq 0$ (TODO muut silotusmenetelmät, perustelu interpolaatiolle ja lambda-arvoille). Vastaavasti todennäköisyys $e$ voidaan estimoida vertaamalla sana-sanaluokka-yhdistelmän frekvenssiä pelkän sanaluokan frekvenssiin:

\begin{align}
e(w_i|t_i) = \frac{f(w_i, t_i)}{f(t_i)}
\label{hmm_param_e}
\end{align}

\subsection{Tuntemattomien sanojen käsittely}

Todennäköisyyden $e$ estimaatti \eqref{hmm_param_e} ei kuitenkaan ole luotettava, jos jokin kohdattu sana ei esiinny harjoitusaineistossa kertaakaan. Tällöin, jos sana $w_i$ on tuntematon, on $e(w_i|t_i)=0$ millä tahansa sanaluokalla $t_i$. Samoin $p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n) = 0$, jos yksikään sanoista $w_i \ldots w_n$ on tuntematon. Jotta vältytään mallin rikkovilta nollaestimaateilta, on tuntemattomien sanojen kohdalla sovellettava jonkinlaista poikkeuskäsittelyä.

Yksinkertaisin ratkaisu on määrätä tuntemattoman sanalle aina harjoitusaineiston yleisin sanaluokka, yleensä substantiivi. Joitain kieliä --- kuten englantia --- tulkittaessa voidaan saavuttaa parempia tuloksia suffiksianalyysin \citep{samuelsson1993} avulla. Tällöin tarkoituksena on hyödyntää sitä seikkaa, että sanan pääte on usein vahva indikaattori sen sanaluokasta. Lisäksi \citet{toutanova2003} ovat esittäneet, kuinka seuraavassa kappaleessa esiteltäviä log-lineaarisia malleja voidaan hyödyntää tuntemattomien sanojen käsittelyssä.

\citet{bikel1999} esittivät vaihtoehtoisen, pseudosanoihin perustuvan menetelmän tuntemattomien sanojen käsittelylle. Menetelmän perusajatuksena on korvata tunnistettavan aineiston kukin tuntematon sana jollakin pseudosanalla, joita on rajallinen määrä. Myös kaikki harvinaiset (vähemmän kuin 5 esiintymää) sanat voidaan korvata pseudosanoilla. Korvaava pseudosana määräytyy aina tuntemattoman sanan ominaisuuksien mukaan: esimerkiksi \textit{isoAlkukirjain}, \textit{lauseenEnsimmäinenSana} sekä \textit{neljäNumeroa} ovat tyypillisiä pseudosanoja. Nyt kun harjoitusaineiston harvinaiset sanat korvataan vastaavilla pseudosanoilla, voidaan tunnistettavan aineiston pseudosanoja käsitellä samoin kuin tavallisia sanoja.


\subsection{Viterbin algoritmi}

Tässä kappaleessa kuvaillaan lyhyesti Viterbin algoritmia, jolla ratkaistaan tehokkaasti em. arvo $\argmax{t_1 \ldots t_n} p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n)$.

\section{Parannukset (tjsp)}

Tähän kuvaukset Cyclic Dependency Network-menetelmästä \citep{toutanova2003}, mahd. ohjaamattomasta oppimisesta \citep{banko2004}. 


\chapter{Log-lineaariset mallit}

TODO


\chapter{Yhteenveto}

TODO Yhteenvedossa kerrataan työn pääkohdat lyhyehkösti johtopäätöksiä tehden. Siinä voi myös esittää pohdintoja siitä, minkälaisia tutkimuksia aiheesta voisi jatkossa tehdä. viittaa kirjallisuuskatsauksen tarkoitukseen ja kertoo ''päätulokset''.
TODO vastataan tutkimuskysymykseen




\begin{thebibliography}{}

\bibitem[Banko \& Moore(2004)]{banko2004}
Banko, M. \& Moore, R. C. 2004. \textit{Part of speech tagging in context}. Proceedings of the 20th conference on Computational Linguistics, ACL, s. 556.

\bibitem[Bikel ym.(1999)]{bikel1999}
Bikel, D. M., Schwartz, R., \& Weischedel, R. M. 1999. \textit{An algorithm that learns what's in a name}. Machine learning, 34(1-3), s.~211--231.

\bibitem[Brants(2000)]{brants2000}
Brants, T. 2000. \textit{TnT - A statistical part-of-speech tagger}. Proceedings of the 6th Applied NLP Conference (ANLP).

\bibitem[Brill(1992)]{brill1992}
Brill, E. 1992. \textit{A simple rule-based part of speech tagger}. Proceedings of the 3rd conference on Applied Computational Linguistics, ACL, Trento, Italy.

\bibitem[Brill(1994)]{brill1994}
Brill, E. 1994. \textit{Some advances in transformation-based part of speech tagging}. AAAI 1994, s.~722-727.

\bibitem[Charniak ym.(1993)]{charniak1993}
Charniak, E., Hendrickson, C., Jacobson, N., \& Perkowitz, M. 1993. \textit{Equations for part-of-speech tagging}. Proceedings of AAAI-93, s.~784--789.

\bibitem[Church(1988)]{church1988}
Church, K. 1988. \textit{A stochastic parts program and noun phrase parser for unrestricted text}. Proceedings of the 2nd conference on Applied Natural Language Processing, s.~136--143.

\bibitem[Cutting ym.(1992)]{cutting1992}
Cutting, D., Kupiec, J., Pedersen, J. \& Sibun, P. 1992. \textit{A Practical Part-of-Speech Tagger}. Proceedings of the 3rd conference on Applied Natural Language Processing, s.~133--140.

\bibitem[DeRose(1988)]{derose1988}
DeRose, S. J. 1988. \textit{Grammatical category disambiguation by statistical optimization}. Computational Linguistics, 14(1), s.~31--39.

\bibitem[Garside(1987)]{garside1987}
Garside, R. 1987. \textit{The CLAWS word-tagging system}. Teoksessa R. Garside, G. Leech \& G. Sampson (toim.) The Computational Analysis of English: A Corpus-based Approach. London: Logman, s.~30-41.

\bibitem[Greene \& Rubin(1971)]{greene1971}
Greene, B. B., \& Rubin, G. M. 1971. \textit{Automatic grammatical tagging of English}. Department of Linguistics, Brown University, 1971.

\bibitem[Heckerman ym.(2000)]{heckerman2000}
Heckerman, D., Chickering, D. M., Meek, C., Rounthwaite, R. \& Kadie, C. M. 2000. \textit{Dependency networks for inference, collaborative filtering and data visualization}.
Journal of Machine Learning Research, 1(1), s.~49-75.

\bibitem[Jaynes(1957)]{jaynes1957}
Jaynes, E. T. 1957. \textit{Information Theory and Statistical Mechanics}. Physical Review, 106, s.~620-630.

\bibitem[Manning(2011)]{manning2011}
Manning, C. D. 2011. \textit{Part-of-Speech Tagging from 97\% to 100\%: Is It Time for Some Linguistics?} Proceedings of the 12th international conference on Computational linguistics and intelligent text processing, 1, s.~171--189.

\bibitem[Manning \& Sch\"{u}tze(1999)]{manning1999}
Manning, C. D. \& Sch\"{u}tze, H. 1999. \textit{Foundations of statistical natural language processing}.
Cambridge, MA. MIT Press

\bibitem[Marcus ym.(1993)]{marcus1993}
Marcus, M. P., Marcinkiewicz, M. \& Santorini, B. 1993. \textit{Building a large annotated corpus of English: the Penn treebank}. Computational Linguistics, 19(2), s.~313-330.

\bibitem[Merialdo(1994)]{merialdo1994}
Merialdo, B. 1994. \textit{Tagging English text with a probabilistic model}. Computational Linguistics, 20(2), s.~155-171.

\bibitem[Ng ja Jordan(2002)]{ng2002}
Ng, A. Y. \& Jordan, M. 2002. \textit{On Discriminative vs. Generative Classifiers: A comparison of logistic regression and Naive Bayes}. In NIPS 14.

\bibitem[''POS Tagging State of the Art''(2013)]{aclwiki2013}
\textit{POS Tagging State of the Art}. 2013. The Wiki of the Association for Computational Linguistics.
Haettu 28.10.2013, osoitteesta \url{aclweb.org/aclwiki/index.php?title=POS_Tagging_(State_of_the_art)}

\bibitem[Rabiner(1989)]{rabiner1989}
Rabiner, L. R. 1989. \textit{A tutorial on Hidden Markov Models and selected applications in speech recognition}. Proceedings of the IEEE, 77(2), s.~257-285.

\bibitem[Ratnaparkhi(1996)]{ratnaparkhi1996}
Ratnaparkhi, A. 1996. \textit{A maximum entropy model for part-of-speech tagging}. Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP), University of Pennsylvania.

\bibitem[Ratnaparkhi(1997)]{ratnaparkhi1997}
Ratnaparkhi, A. 1997. \textit{ A simple introduction to maximum entropy models for natural language processing}.
Technical Report 97-08, Institute for Research in Cognitive Science, University of Pennsylvania, 1997.

\bibitem[Samuelsson(1993)]{samuelsson1993}
Samuelsson, C. 1993. \textit{Morphological tagging based entirely on Bayesian inference}. Proceedings of the 9th Nordic Conference on Computational Linguistics NODALIDA-93.

\bibitem[Shen ym.(2007)]{shen2007}
Shen, L., Satta, G. \& Joshi, A. 2007. \textit{Guided learning for bidirectional sequence classification}. In: ACL 2007. (2007)

\bibitem[Spoustova ym.(2009)]{spoustova2009}
Spoustova, D.j., Hajic, J., Raab, J. \& Spousta, M. 2009. \textit{Semi-supervised training for the averaged perceptron POS tagger}. Proceedings of the 12th Conference of the
European Chapter of the ACL (EACL 2009), s.~763-711.

\bibitem[Toutanova ym.(2003)]{toutanova2003}
Toutanova, K., Klein, D., Manning, C.D. \& Singer, Y. 2003. \textit{Feature-rich part-of-speech tagging with a cyclic dependency network}. In: NAACL 3. (2003), s.~252-259

\bibitem[Tseng ym.(2005)]{tseng2005}
Tseng, H., Jurafsky, D. \& Manning, C. 2005. \textit{Morphological features help POS tagging of unknown words across language varities}. Proceedings of the 4th SIGHAN bakeoff.

\end{thebibliography}

\end{document}
