% !TeX encoding = utf8
%
% [ Tiedostossa käytetty merkistö on utf8, vaihtoehtoisesti voisi olla esim.]
% [ ISO 8859-1 eli Latin 1. Ylläoleva rivi ]
% [ tarvitaan, jos käyttää MiKTeX-paketin mukana tulevaa TeXworks-editoria. ]
%
% TIETOTEKNIIKAN KANDIDAATINTUTKIELMA
%
% Yksinkertainen LaTeX2e-mallipohja kandidaatintutkielmalle.
% Käyttää Antti-Juhani Kaijanahon kirjoittamaa gradu3-dokumenttiluokkaa.
%
% Jos kirjoitat pro gradu -tutkielmaa, tee mallipohjaan seuraavat muutokset:
%  - Poista dokumenttiluokasta optio bachelor .
%  - Poista makro \type .
%  - Lisää suuntautumisvaihtoehto makrolla \studyline .
%  - Lisää tieto ohjaajasta makrolla \supervisor .

\documentclass[utf8,bachelor,manualbib]{gradu3}

\usepackage{palatino} % valitaan oletusfonttia hieman tyylikkäämpi fontti

\usepackage{graphicx} % tarvitaan vain, jos halutaan mukaan kuvia
\usepackage{amsmath}  % tarvitaan käytettäessä monimutkaisten matemaattisten kaavojen ja \eqref-kaavaviittauksen yhteydessä
\usepackage{url} % tarvitaan \url-komentoa varten
\usepackage{booktabs}

\usepackage{amsfonts}
\usepackage{enumitem}
\usepackage{eucal}
\usepackage{pbox}
\usepackage{comment}
\usepackage{float}
\restylefloat{table}

% Otetaan käyttöön author-date-järjestelmän mukaiset lähdeviittaukset:
\usepackage{natbib}
% Vaihdetaan kirjoittajan nimen ja vuosiluvun väliseksi erottimeksi
% välilyönti (oletuserottimena on pilkku):
%\bibpunct{(}{)}{;}{a}{}{,}

\newcommand{\argmax}[1]{\underset{#1}{\operatorname{arg}\,\operatorname{max}}\;}

% HUOM! Tämän tulee olla viimeinen \usepackage koko dokumentissa!
\usepackage[bookmarksopen,bookmarksnumbered,linktocpage]{hyperref}
\setcounter{tocdepth}{2}

% &-merkin sijaan ''ja'' - tähän on varmaan olemassa joku parempikin tapa
\defcitealias{giesbrecht2009}{Giesbrecht ja Evert (2009)}
\defcitealias{ng2002}{Ng ja Jordan (2002)}
\defcitealias{ngai2001}{Ngai ja Florian (2001)}
\defcitealias{volk1998}{Volk ja Schneider (1998)}
\defcitealias{roche1995}{Roche ja Schabes (1995)}
\defcitealias{schneider1998}{Schneider ja Volk (1998)}

\begin{document}

\title{Sanaluokkien automaattisen tunnistamisen menetelmät}

\translatedtitle{Methods for automated part-of-speech tagging}

%\studyline{}
\avainsanat{kieliteknologia, luonnollisten kielten käsittely, sanaluokkien tunnistaminen, koneoppiminen}
\keywords{computational linguistics, natural language processing, part-of-speech tagging, machine learning}
\tiivistelma{Tiivistelmä on tyypillisesti 5-10 riviä pitkä esitys työn pääkohdista (tausta, tavoite, tulokset, johtopäätökset).
}
\abstract{Englanninkielinen versio tiivistelmästä.
}

\author{Aleksi Pekkala}
\contactinformation{\texttt{aleksi.v.a.pekkala@student.jyu.fi}}
% jos useita tekijöitä, anna useampi \author-komento
%\supervisor{Kirsi Valjus}
% jos useita ohjaajia, anna useampi \supervisor-komento
%\type{kandidaatintutkielma} % tämän makron oletus on "pro gradu -tutkielma" ja bachelor-optiolla kandidaatintutkielma

\maketitle
  
\mainmatter


\chapter{Johdanto}


Sanaluokkien automaattinen tunnistaminen (engl. \emph{part-of-speech tagging}) tarkoittaa sanojen sanaluokkien tunnistamista tekstiyhteyden perusteella.  Tunnistamisprosessissa tarkastellaan tekstiaineistoa, kuten
\[a\:black\:cat\:jumped\:on\:the\:table\]
jonka perusteella pyritään päättelemään se sanaluokkien sarja, joka todennäköisimmin vastaa kyseistä aineistoa; tässä tapauksessa tuloksena voisi olla esimerkiksi
\[Det\:Adj\:Noun\:Verb\:Prep\:Det\:Noun\]
Sanaluokkien tunnistaminen on laajuudeltaan rajallinen ongelma: tarkoituksena ei ole jäsentää kokonaisia lauserakenteita tai tulkita lauseiden merkitystä --- tarkastelun alla ovat vain yksittäisten sanojen leksikaaliset kategoriat. Sanaluokkien tunnistaminen on kuitenkin välttämätön ensimmäinen askel monissa luonnollisten kielten käsittelyprosesseissa, ja siten yksi aihealueen keskeisistä osaongelmista. Lisäksi tunnistusongelman eri ratkaisut ovat usein suoraan siirrettävissä muiden yksikäsitteistämisongelmien, kuten sanan merkitysanalyysin piiriin \citep{brill1995}.

Rajallisen laajuutensa myötä sanaluokkien tunnistaminen on paljon helpommin lähestyttävä ongelma kuin kielen täydellinen ymmärtäminen, ja sen ratkaisemiseksi onkin kehitetty useita kohtuullisen luotettavia menetelmiä. Täysin ratkaistusta ongelmasta ei kuitenkaan voida puhua, sillä yksikään tunnettu menetelmä ei vielä saavuta täydellistä tunnistustarkkuutta. \citep[s. 342]{manning1999}

Sanaluokkien tunnistajia käytetään monissa erilaisissa luonnollisiin kieliin liittyvissä sovelluksissa, ja tunnistajalle asetetut vaatimukset vaihtelevat sovelluksittain. Myös tunnistettavien aineistojen välillä on valtavasti poikkeamia, esim. kielten sekä tekstilajien osalta. Lisäksi havaitaan, että nykyisten tunnistusmenetelmien saavuttamat tunnistustarkkuudet liikkuvat kaikki suunnilleen samoissa lukemissa. Kun ilmiselvin valintakriteeri on näin poissuljettu, on tehokkaimman menetelmän valinta vaikeampaa. Tunnistusmenetelmien toimintaperiaatteiden vaihdellessa merkittävästi on kuitenkin väistämätöntä, että jotkin menetelmät soveltuvat toisia paremmin tiettyihin tunnistustehtäviin. Tässä tutkielmassa pyritäänkin selventämään sitä, millaisia eri ratkaisuja sanaluokkien tunnistusongelmaan on olemassa ja mitkä ovat niiden tärkeimmät erot. Menetelmien suhteelliset ominaisuudet johdetaan tarkastelemalla lähemmin kunkin menetelmän toimintaa sekä menetelmään liittyvää tutkimuskirjallisuutta. 

Tutkielma rakentuu seuraavasti: toisessa luvussa annetaan lyhyt johdanto sanaluokkien tunnistamiseen ja sen haasteisiin. Luvuissa 3-4 tarkastellaan kahta erilaista lähtökohtaa tunnistusongelman ratkaisemiseksi: sääntöpohjaista Brillin tunnistinta sekä tilastollista Markovin piilomalleihin perustuvaa tunnistinta. Luvuissa esitellään menetelmien keskeiset ominaisuudet, sekä pyritään hahmottamaan niiden suhteelliset vahvuudet ja heikkoudet. Lopuksi vielä kootaan yhteen menetelmistä kerätyt huomiot ja esitellään johtopäätökset.

TODO maininta menetelmien valintaperusteista ja/tai esitysjärjestyksestä


\chapter{Sanaluokkien automaattinen tunnistaminen}

Sanaluokkien tunnistaminen on tärkeä ja käytännöllinen ongelma, joka kohdataan lähes kaikissa luonnollisten kielten käsittelyyn liittyvissä tehtävissä. Tällaisia tehtäviä ovat muunmuassa puheentunnistus, konekääntäminen sekä semanttinen haku ja analyysi. Kyseisissä tehtävissä sanaluokkien tunnistaja toimii jonkin laajemman prosessointiketjun alkupäässä, koko prosessille välttämättömänä esikäsittelijänä, joka mahdollistaa syötteen jatkokäsittelyn korkeammalla tasolla. Jatkokäsittelyn tyypillisin seuraava vaihe on tekstin jäsentäminen eli lauserakenteiden tunnistaminen. Oikeiden lauserakenteiden tunnistamisen kannalta on oleellista, että lauseiden sanaluokat on tunnistettu mahdollisimman virheettömästi: yksikin virheellinen sanaluokka voi tehdä oikean lauserakenteen tunnistamisesta mahdotonta, ja siten vääristää lauseen tulkittua merkitystä.


\section{Miksi sanaluokkien tunnistaminen on ongelmallista?}

Sanaluokkien tunnistaminen voi intuitiivisesti tuntua helpolta, mutta tehtävän automaatiota hankaloittavat kaksi oleellista ongelmaa: sanojen monitulkintaisuus sekä tuntemattomat sanat. Esimerkiksi lauseissa
\[Time\: flies\: like\: an\: arrow.\]
\[Fruit\: flies\: like\: a\: banana.\]
sana \textit{flies} esiintyy ensin verbinä ja sitten substantiivina. Sanan \textit{time} ilmeisin sanaluokka on substantiivi, mutta se voidaan mieltää myös imperatiiviverbinä, jolloin lauseen merkitys muuttuu täysin. Itse asiassa kummatkin esimerkkilauseet voidaan tulkita kymmenin eri tavoin, joista ilmeisimmän tulkinnan valitseminen automaattisesti on haastavaa. Lisäksi, vaikka tosielämässä tulkittavat lauseet ovat harvoin yhtä ongelmallisia kuin edellä mainitut lingvistiset esimerkkilauseet, on monitulkintaisuus hyvin yleistä: arviolta 40\% englanninkielisen proosan sanastosta voidaan luokitella useampaan kuin yhteen sanaluokkaan \citep{derose1988}. 

Jatkokäsittelyn kannalta automaattisen tunnistajan oleellisin tehtävä onkin valita kaikista mahdollisista sanaluokista se, joka tuottaa luontevimman tulkinnan. Tällaisen yksikäsitteistämisen mahdollistavat luonnollisten kielten sisäänrakennetut rajoitteet, jotka voidaan jakaa lokaaleihin sekä kontekstuaalisiin vihjeisiin: lokaaleista vihjeistä ilmeisin on itse sana (''sana \textit{can} on on todennäköisemmin modaaliverbi kuin substantiivi''), mutta päätelmiä voidaan tehdä myös mm. sanan prefiksin, suffiksin tai kirjainten koon perusteella. Kontekstuaalisia vihjeitä ovat kaikki lauseen muut sanat sanaluokkineen: esimerkiksi sana \textit{fly} on todennäköisimmin substantiivi, jos edeltävä sana on artikkeli.

On tärkeää huomata, ettei sanaluokkien tunnistaminen itsessään ole ratkaisu kieliopilliseen monitulkintaisuuteen: monitulkintaisuudella on useita tasoja, joista osaa käsitellään vielä prosessointiketjun myöhemmissä vaiheissa. Esimerkiksi syntaktinen eli rakenteellinen monitulkintaisuus on ongelma, joka on huomattavasti helpompi ratkaista lauseiden jäsennyksen yhteydessä. Sanaluokkien tunnistamista ei myöskään tule sekoittaa semanttiseen yksikäsitteistämiseen eli sanan merkityksen selvittämiseen: esimerkiksi sana \textit{mouse} on semanttisesti monitulkintainen, vaikka sen sanaluokka tunnettaisiinkin. Sanaluokkien tunnistamisen rooli on pikemminkin rajata mahdollisten tulkintojen määrää prosessointiketjun alkupäässä, jotta myöhemmissä vaiheissa vältytään ylimääräiseltä työltä. \citep[s. 341]{manning1999}

Monitulkintaisuuden lisäksi toinen merkittävä ongelma on tuntemattomien eli harjoitusaineistosta puuttuvien sanojen käsitteleminen. Englannin kielessä yleisiä tuntemattomia sanoja ovat erisnimet sekä puhekieliset, vieraskieliset ja muut harvinaiset ilmaisut. Tällaisia sanoja kohdataan usein, ja koska niitä koskevaa tilastollista informaatiota tai sääntöjä ei tunneta, joudutaan turvautumaan jonkinlaiseen poikkeuskäsittelyyn. Useat tunnistajat hyödyntävät tuntemattomien sanojen kohdalla kieliopillisia ominaisuuksia: yksinkertainen menetelmä on määrätä sanalle se sanaluokka, johon tuntemattomien sanojen on havaittu todennäköisimmin kuuluvan, eli yleensä substantiivi. Parempia tuloksia on saavutettu määrittämällä tuntemattoman sanan sanaluokka sen päätteen perusteella; esimerkiksi englannin kielen \emph{able}-päätteiset sanat ovat hyvin todennäköisesti adjektiiveja \citep{samuelsson1993}. Menetelmä ei kuitenkaan sovellu kaikille kielille: esimerkiksi \citet{tseng2005} osoittavat, että kiinan kielessä esiintyy huomattavan suuri määrä yleisiä affikseja, poiketen englannin ja saksan kielistä, joissa affiksit ovat vahva indikaattori sanan sanaluokasta.


\section{Automaattisten tunnistajien suorituskyky}

Kuten mainittua, nykyisten tunnistimien saavuttama tunnistustarkkuus on hieman yli 97\%  \citep[mm.][]{toutanova2003, spoustova2009, sogaard2011}. \citet{manning2011} kuitenkin osoittaa, että kyseistä tulosta ei ole syytä tulkita liian optimistisesti: esimerkiksi lukuisat välimerkit ja muut yksikäsitteiset elementit vääristävät evaluaatiotuloksia. Lisäksi useissa tekstilajeissa, kuten uutisiartikkeleissa, lauseiden keskipituus on yli 20 sanaa, jolloin edellä mainitullakin tunnistustarkkuudella jokaisessa lauseessa on keskimäärin yksi virhe \citep{manning1999}. Artikkelissa huomautetaankin, että realistisempaa olisi tarkastella automaattisten tunnistimien kykyä tunnistaa kokonaiset lauseet oikein, sillä pienikin virhe lauseessa voi vahingoittaa tunnistajan hyödyllisyyttä myöhempien prosessointivaiheiden kannalta; tällä saralla tunnistajat saavuttavat noin 55-57\% tarkkuuden, mikä on huomattavasti vaatimattomampi tulos. Lisäksi \citetalias{giesbrecht2009} ovat osoittaneet, että kyseiset huipputulokset ovat saavutettavissa vain hyvin keinotekoisissa koetilanteissa: todellisissa käyttötapauksissa tunnistimien tarkkuus laskee alle 93 prosentin, tarkkuuden vaihdellessa merkittävästi tekstilajeittain.

Tarkkuustuloksia arvioidessa tulee myös ottaa huomioon varsin korkea lähtötaso: jo yksinkertaisimmalla metodilla, eli valitsemalla kullekin sanalle se sanaluokka, joka esiintyy harjoitusaineistossa useiten annetun sanan yhteydessä, saavutetaan noin 90\% tunnistustarkkuus \citep{charniak1993}. On myös mielenkiintoista huomata, että edes ammattilaisten käsin luokittelemat aineistot eivät saavuta täydellistä tunnistamistarkkuutta: yksittäisen ihmisen tunnistustarkkuuden on arvioitu olevan noin 97\% \citep{manning2011}, mikä vastaa edellä mainittua automaattisten tunnistimien huipputulosta.
 
\section{Sanaluokkien tunnistajan vaatimukset}

Jotta tunnistajaa voidaan käyttää laajan kielenprosessointijärjestelmän komponenttina, tulee sen toteuttaa seuraavat ominaisuudet ~\citep{cutting1992}: 

\begin{description}[labelindent=1cm]
 \item[Kestävyys] Tunnistajan tulee kyetä selviytymään kaikista tekstisyötteen mahdollisista poikkeamista, kuten otsikoista, taulukoista sekä tuntemattomista sanoista.
 \item[Tehokkuus] Voidakseen käsitellä laajoja tekstiaineistoja tunnistajan tulee toimia lineaarisessa ajassa. Myös tunnistajan mahdollisen opettamisen tulisi onnistua kohtuullisen nopeasti.
 \item[Tarkkuus] Tunnistajan tulee kyetä ehdottamaan sanaluokka jokaista annettua sanaa kohden.
 \item[Viritettävyys] Tunnistajan tulee osata hyödyntää erilaisia kielitieteellisiä huomioita siten, että tunnistajan tekemiä virheitä voidaan paikata määrittämällä sopivia vihjeitä.
 \item[Uudelleenkäytettävyys] Tunnistajan tulee rakentua siten, että sen kohdistaminen uudelle kielelle, aineistolle tai sanaluokkasetille on mahdollisimman vaivatonta.
\end{description}

\section{Harjoitusaineisto ja sanaluokkasetit}

Sanaluokkien tunnistaminen on luonteeltaan sarjanluokitteluongelma, joka taas on yksi koneoppimisen (tarkemmin hahmontunnistuksen) aliongelmatyypeistä. Tämän seurauksena nykyiset sanaluokkien tunnistusmenetelmät perustuvat usein ohjattuun oppimiseen, missä tunnistimet harjoitetaan jonkinlaisella harjoitusaineistolla ennen käyttöä. Sanaluokkien tunnistimille syötettävä harjoitusdata koostuu suurista tekstiaineistoista (engl. \textit{corpus}), joissa jokaisen sanan yhteyteen on merkattu oikea sanaluokka. Nykyisin ehkä yleisimmin käytetty englanninkielinen harjoitusaineisto on \textit{Penn Treebank}-aineisto \citep{marcus1993}, joka sisältää noin viiden miljoonan sanan edestä uutisartikkeleita, kaunokirjallisuutta, tieteellisiä julkaisuja ynnä muita tekstilajeja.

Tunnistusongelmaan on olemassa myös ohjaamattomaan oppimiseen perustuvia ratkaisuja, jotka eivät vaadi ennalta luokiteltua harjoitusaineistoa. Toisaalta tällaiset menetelmät ovat väistämättä alttiimpia virheille kuin vastaavat ohjatun oppimisen menetelmät. Joissain tapauksissa --- esimerkiksi harvinaisia kieliä analysoitaessa --- luokiteltua harjoitusaineistoa ei kuitenkaan ole saatavilla, jolloin ohjaamaton oppiminen on ainoa vaihtoehto.

Tunnistamisessa käytetyt sanaluokat määräytyvät yleensä harjoitusaineiston mukaan: esimerkiksi Penn Treebank-aineiston käyttämä sanaluokkasetti koostuu 48 sanaluokasta, joista 12 ovat välimerkkejä. On tärkeää huomata, että käytettävän sanaluokkasetin laajuus vaikuttaa suoraan tunnistustarkkuuteen: mitä enemmän sanaluokkia, sitä suurempi mahdollisuus monitulkintaisuuteen. Toisaalta sanaluokkien tunnistamisen tuottama lingvistinen informaatio on sitä arvokkaampaa, mitä tarkempi jaottelu eri sanaluokkien välillä on. \citep{marcus1993}

TODO esimerkkipätkä harjoitusaineistosta, jotain siitä miksi suomen kieli ym. vahvasti synteettiset/agglutinatiiviset kielet ovat hankalia sanaluokkien tunnistamisen kannalta.

\begin{comment}
%{\renewcommand{\arraystretch}{0.8}
\begin{table}[H]\footnotesize
  \caption{Penn Treebank-aineiston sanaluokkasetti. Lähde: \citet{marcus1993}}
  \begin{tabular}{| r l l | r l l |}
\hline 1. & CC & Coordinating conjunction & 25. & TO & to \\
2. & CD & Cardinal number & 26. & UH & Interjection \\
3. & DT & Determiner & 27. & VB & Verb, base form \\
4. & EX & Existential there & 28. & VBD & Verb, past tense \\
5. & FW & Foreign word & 29. & VBG & Verb, gerund/present \\
6. & IN & \pbox{20cm}{Preposition/subordinating \\ participle conjunction} & 30. & VBN & Verb, past participle \\
7. & JJ & Adjective & 31. & VBP & Verb, non-3rd ps. sing. present \\
8. & JJR & Adjective, comparative & 32. & VBZ & Verb, 3rd ps. sing. present \\
9. & JJS & Adjective, superlative & 33. & WDT & wh-determiner \\
10. & LS & List item marker & 34. & WP & wh-pronoun \\
11. & MD & Modal & 35. & WP\$ & Possessive wh-pronoun \\
12. & NN & Noun, singular or mass & 36. & WRB & wh-adverb \\
13. & NNS & Noun, plural & 37. & \# & Pound sign \\
14. & NNP & Proper noun, singular & 38. & \$ & Dollar sign \\
15. & NNPS & Proper noun, plural  & 39. & . & Sentence-final punctuation \\
16. & PDT & Predeterminer & 40. & , & Comma \\
17. & POS & Possessive ending & 41. & : & Colon, semi-colon \\
18. & PRP & Personal pronoun & 42. & ( & Left bracket character \\
19. & PP\$  &Possessive pronoun & 43. & ) & Right bracket character \\
20. & RB & Adverb & 44. & " & Straight double quote \\
21. & RBR & Adverb, comparative & 45. & ' & Left open single quote \\
22. & RBS & Adverb, superlative & 46. & " & Left open double quote \\
23. & RP & Particle & 47. & ' & Right close single quote \\
24. & SYM & Symbol (mathematical or scientific)& 48. & " & Right close double quote \\ \hline
  \end{tabular}
  \label{table:penntagset}
\end{table}
\end{comment}


\chapter{Sääntöpohjaiset menetelmät}

Ensimmäiset automaattiset sanaluokkatunnistimet (mm. \citealp{greene1971}) olivat lähtöisin kielitieteen piiristä, ja ne perustuivat pitkälti käsin laadittuihin kieliopillisiin sääntöihin. Tällainen sääntöpohjainen menetelmä toimii seuraavasti: ensin kunkin sanan mahdolliset sanaluokat haetaan sanakirjasta tai vastaavasta tietolähteestä. Seuraavaksi monitulkintaisten sanojen kohdalla sovelletaan valmiita kielioppisääntöjä sanaluokkien poissulkemiseen, kunnes jäljelle on vain yksi sanaluokka. Kielioppisäännöt voivat hyödyntää sekä lokaaleja että kontekstuaalisia vihjeitä; tyypillisiä sääntöjä ovat esimerkiksi

\begin{enumerate}
\item \textit{hylkää sanaluokka $x$ jos sanalla on iso alkukirjain} (lokaali vihje), sekä
\item \textit{hylkää sanaluokka $x$, jos edeltävä sanaluokka on $y$} (kontekstuaalinen vihje).
\end{enumerate}

Kyseisen lähestymistavan ilmeisin heikkous on vaaditun manuaalisen työn määrä: erilaisille aineistoille tulee aina luoda uusi, aineiston kielelle ja tyylille spesifi sääntökokoelma. Huomattavan työpanoksen lisäksi sääntöpohjainen menetelmä vaatii myös ymmärryksen tulkittavan aineiston kieliopillisista erikoispiirteistä, jotta luodut säännöt tuottavat toivotun tuloksen. Puhtaasti sääntöpohjaisilla menetelmillä voidaan saavuttaa --- sääntöjen määrästä riippuen --- korkeita tarkkuustuloksia, mutta kyseiset tulokset eivät ole siirrettävissä erilaisille aineistoille ilman mittavia muutostöitä.

Sääntöpohjaisten menetelmien puutteiden vuoksi useimmat nykyiset sanaluokkien tunnistajat perustuvat tilastollisiin menetelmiin: sanaluokkia koskeva tilastollinen informaatio voidaan poimia harjoitusaineistosta automaattisesti, siinä missä sääntöjen laatiminen vaatii lingvististä asiantuntemusta ja manuaalista työtä. Sääntöpohjaisilla menetelmillä on kuitenkin joitakin etuja tilastollisiin menetelmiin verrattuna: ensinnäkin kielioppisääntöjen tallentaminen vaatii huomattavasti vähemmän tallennustilaa kuin vastaava tilastollinen informaatio. Tilastollista informaatiota on myös hankalampi tulkita ja käsitellä kuin yksinkertaisia kielioppisääntöjä, jonka myötä tunnistusvirheiden tunnistaminen ja korjaaminen on helpompaa kielioppisääntöjä käytettäessä. \citep{brill1992}

\section{Brillin sääntöpohjainen sanaluokkatunnistin}

\citet{brill1992} esittää artikkelissaan vaihtoehtoisen lähestymistavan, joka pohjautuu varhaisimpien tunnistusmenetelmien tavoin kieliopillisiin sääntöihin. Aikaisemmista sääntöpohjaisista menetelmistä poiketen sääntöjä ei kuitenkaan syötetä manuaalisesti, vaan tunnistin oppii ne automaattisesti oikeilla sanaluokilla merkitystä harjoitusaineistosta. Menetelmän kantava idea on (1) aloittaa jostakin yksinkertaisesta ratkaisusta, (2) tunnistaa tehdyt virheet ja (3) inkrementaalisesti soveltaa virheitä korjaavia transformaatiosääntöjä, kunnes ne eivät enää paranna kokonaistarkkuutta.

Brillin tunnistinta alustettaessa harjoitusaineisto jaetaan kahteen osaan, joista pienempää käytetään niin sanottuna sääntöaineistona (engl. \textit{patch corpus}) ja suurempaa varsinaisena harjoitusaineistona. Tunnistimen alustus alkaa siten, että sääntöaineiston kukin sana luokitellaan ensin sillä sanaluokalla, joka useimmiten esiintyy sanan yhteydessä harjoitusaineistossa. Tuntemattomien sanojen kohdalla sanaluokka määräytyy sanan kolmen viimeisen kirjaimen mukaan: esimerkiksi kaikki \textit{ous}-päätteiset tuntemattomat sanat luokitellaan adjektiiveiksi, koska harjoitusaineiston \textit{ous}-päätteiset sanat ovat useimmiten adjektiiveja. Lisäksi kaikki isolla alkukirjaimella alkavat tuntemattomat sanat luokitellaan erisnimiksi. Tämän yksinkertaisen menetelmän tarkkuus on noin 92\%. \citep{brill1992}

Seuraavaksi verrataan edellä mainitulla menetelmällä tunnistettuja sanaluokkia sääntöaineiston oikeisiin sanaluokkiin. Vertailun tuloksena saadaan lista virheistä muodossa $<tag_a, tag_b, number>$, josta ilmenee montako kertaa jokin sana tunnistettiin luokkaan $tag_a$, kun oikea sanaluokka olisi ollut $tag_b$. Nyt käyttämällä valmiita sääntörunkoja voidaan laskennallisesti selvittää se transformaatiosääntö, joka laskee virheprosenttia eniten. Kunkin virhe-sääntörunko-parin muodostamaa sääntöä siis sovelletaan vuorostaan sääntöaineistoon, ja säännön arvo lasketaan vähentämällä korjattujen virheiden määrästä mahdollisesti aiheutettujen uusien virheiden lukumäärä. \citet{brill1992} käyttää artikkelissaan seuraavia sääntörunkoja:

Vaihda sanaluokka $a$ sanaluokkaan $b$, kun:

\begin{enumerate}
\item Edellinen (seuraava) sanaluokka on $z$.
\item Edellistä edeltävä (seuraavaa seuraava) sanaluokka on $z$. 
\item Jokin kahdesta edellisestä (seuraavasta) sanaluokasta on $z$.
\item Jokin kolmesta edellisestä (seuraavasta) sanaluokasta $z$.
\item Edellinen sanaluokka on $z$ ja seuraava sanaluokka on $w$.
\item Edellinen (seuraava) sanaluokka on $z$ ja seuraavaa seuraava (edellistä edeltävä) sanaluokka on $w$. 
\item Nykyinen sana alkaa isolla (pienellä) alkukirjaimella.
\item Edellinen sana alkaa isolla (pienellä) alkukirjaimella.
\end{enumerate}

Kun arvokkain transformaatiosääntö on löydetty, sääntö laitetaan muistiin ja sääntöaineistoon tehdään löydetyn säännön mukaiset muutokset. Prosessia jatketaan keräämällä taas lista sääntöaineiston tunnistusvirheistä, ja etsimällä uusi paras transformaatiosääntö. Tätä toistetaan, kunnes ei enää löydetä sellaista sääntöä, joka tuottaisi enemmän korjauksia kuin aiheuttaisi uusia virheitä. Tällöin alustamisprosessi on valmis, ja tuloksena saatuja transformaatiosääntöjä voidaan soveltaa uuden aineston tunnistamiseen seuraavasti: ensin aineisto luokitellaan mainitulla yksinkertaisella menetelmällä. Tämän jälkeen aineistoon sovelletaan kutakin alustusvaiheessa löydettyä transformaatiosääntöä, jolloin virheprosentti laskee. \citep{brill1992}

% Esimerkit löytyneistä säännöistä
\begin{comment}
\begin{table}[H]
\centering
\caption{10 ensimmäistä transformaatiosääntöä Penn Treebank-aineistolla harjoittaessa. Lähde: \citet{brill1995}}
\begin{tabular}{|c|c|c|c|}
\hline
\# & Mistä & Mihin & Ehto \\ \hline
1 & NN & VB & Edellinen sanaluokka on $TO$ \\
2 & VBP & VB & Jokin kolmesta edellisestä sanaluokasta on $MD$ \\
3 & NN & VB & Jokin kahdesta edellisestä sanaluokasta on $MD$ \\
4 & VB & NN & Jokin kahdesta edellisestä sanaluokasta on $DT$ \\
5 & VBD & VBN & Jokin kolmesta edellisestä sanaluokasta on $VBZ$ \\
6 & VBN & VBD & Edellinen sanaluokka on $PRP$ \\
7 & VBN & VBD & Edellinen sanaluokka on $NNP$ \\
8 & VBD & VBN & Edellinen sanaluokka on $VBD$ \\
9 & VBP & VB & Edellinen sanaluokka on $TO$ \\
10 & POS & VBZ & Edellinen sanaluokka on $PRP$ \\ \hline
\end{tabular}
\end{table}
\end{comment}

\section{Brillin tunnistimen laajentaminen}

Yksi Brillin alkuperäisen tunnistimen puutteista on se, että käytetyt sääntörungot huomioivat pelkästään sanaluokkien väliset suhteet: itse sanoihin liittyvää kontekstuaalista informaatiota ei käsitellä lainkaan. Tällöin merkittävä osa kielen kontekstuaalisista vihjeistä jää hyödyntämättä. Kyseistä puutetta voidaan paikata laajentamalla tunnistinta seuraavilla sääntörungoilla:

Vaihda sanaluokka $a$ sanaluokkaan $b$, kun:
\begin{enumerate}
\item Edellinen (seuraava) sana on $w$.
\item Edellistä edeltävä (seuraavaa seuraava) sana on $w$. 
\item Jokin kahdesta edellisestä (seuraavasta) sanasta on $w$.
\item Nykyinen sana on $w$ ja edellinen (seuraava) sana on $x$.
\item Nykyinen sana on $w$ ja edellinen (seuraava) sanaluokka on $z$.
\end{enumerate}

Tunnistimen leksikalisointi edellä mainituilla säännöillä vähentää tunnistusvirheiden määrää noin 10 prosentilla. \citep{brill1994}

Brillin tunnistimen toinen merkittävä puute on tuntemattomien sanojen heikko tunnistustarkkuus. Tämä ei ole varsinaisesti yllättävää, sillä edellä kuvailtu sanojen pääteliitteisiin perustuva tuntemattomien sanojen erikoiskäsittely jää melko pinnalliseksi: lokaaleista vihjeistä huomioidaan vain pääte sekä alkukirjaimen koko, ja kontekstuaaliset vihjeet sivuutetaan täysin. Tätäkin ongelmaa voidaan lieventää laajentamalla tunnistinta uusilla sääntörungoilla: 

Vaihda tuntemattoman sanan sanaluokka $a$ sanaluokkaan $b$, kun:
\begin{enumerate}
\item Etuliitteen $x$, $|x| \leq 4$, poistamisesta seuraa uusi sana.
\item Sanan ensimmäiset (1,2,3,4) kirjainta ovat $x$. 
\item Pääteliitteen $x$, $|x| \leq 4$, poistamisesta seuraa uusi sana.
\item Sanan viimeiset (1,2,3,4) kirjainta ovat $x$. 
\item Merkkijonon $x$ lisäämisestä sanan pääteliitteeksi seuraa uusi sana ($|x| \leq 4$).
\item Merkkijonon $x$ lisäämisestä sanan etuliitteeksi seuraa uusi sana ($|x| \leq 4$).
\item Edellinen (seuraava) sana on $w$.
\item Sana sisältää kirjaimen $z$.
\end{enumerate}

Huomataan, ettei yksikään sääntörunko ota kantaa sanaluokkiin, koska tuntemattomat sanat käsitellään ennen varsinaisten transformaatiosääntöjen soveltamista. Näiden kahden lisäyksen myötä Brillin tunnistin saavuttaa 96,6\% tunnistustarkkuuden, missä tuntemattomien sanojen tunnistustarkkuus on 85\%. \citep{brill1994, brill1995}

Edellisten puutteiden lisäksi Brillin tunnistin on itsessään suhteellisen epätehokas: \citetalias{ngai2001} mainitsevat, että tunnistimen harjoittaminen miljoonan sanan aineistolla vie tyypillisesti yli 38 tuntia. Samoin \citetalias{volk1998} raportoivat Brillin tunnistimen harjoittamisen vievän päiviä siinä missä vastaava tilastollinen tunnistin harjoitetaan minuuteissa. Harjoittamisen nopeuttamiseksi on esitetty inkrementaalinen menetelmä, jonka avulla tunnistin skaalautuu paremmin laajoille harjoitusaineistoille \citep{ramshaw1994}. Menetelmässä jokainen transformaatiosääntö sisältää listan niistä sääntöaineiston kohdista, joissa sääntöä voidaan soveltaa. Samoin jokainen sääntöaineiston indeksi sisältää listan kyseisessä kohdassa sovellettaviin sääntöihin. Näiden indeksien avulla vältytään koko sääntöaineiston läpikäymiseltä transformaatiosäännön arvoa laskiessa. Inkrementaaliseen menetelmään perustuva FastTBL-algoritmi suoriutuu mainitusta 38 tunnin harjoittamisesta noin 17 minuutissa \citep{ngai2001}. Harjoittamisen nopeuttamisen lisäksi \citetalias{roche1995} ovat osoittaneet kuinka tunnistimen käyttämistä voidaan nopeuttaa muokkaamalla löydetyt transformaatiosäännöt eräänlaiseksi äärelliseksi automaatiksi: artikkelissa raportoidaan noin 20-kertainen tunnistusnopeus Brillin alkuperäiseen tunnistimeen verrattuna.

\section{Brillin tunnistimen arviointi}

Brillin tunnistin osoittaa, että sääntöpohjaisilla menetelmillä voidaan saavuttaa sekä kilpailukykyisiä tarkkuustuloksia että tilastollisia menetelmiä vastaava helppokäyttöisyys. Tunnistin myös säilyttää kaikki aikaisemmin mainitut sääntöpohjaisten menetelmien edut: transformaatiosäännöt peittoavat vastaavan tilastodatan havainnollisuudessa, kompaktiudessa sekä muokattavuudessa. Yltääkseen esimerkiksi siihen tarkkuuteen, mihin Markovin malleihin perustuva tilastollinen tunnistin vaatii 10 000 todennäköisyyslukemaa, Brillin tunnistin tarvitsee vain 217 transformaatiosääntöä \citep{brill1994}. Tunnistimen kompaktiuden ansiosta sen tuloksia on helpompi analysoida ja tarvittaessa muokata manuaalisesti: esimerkiksi \citetalias{schneider1998} ovat esittäneet, kuinka tunnistimen tarkkuutta voi parantaa huomattavasti hyödyntämällä lisäämällä sääntöjä käsin.  Edellä esitettyjen laajennusten myötä Brillin tunnistin on myös hyvin tehokas.

Koska Brillin tunnistin sisältää itsessään hyvin vähän lingvististä tietoa, se on helposti kohdennettavissa erilaisille aineistoille. Esimerkiksi saksankielisten tekstien analysointiin Brillin tunnistin soveltuu lähes sellaisenaan \citep{volk1998}. \citet{megyesi1999} puolestaan on osoittanut, että tunnistin on siirrettävissä myös agglutinatiivisille kielille käytettyjä sääntörunkoja muokkaamalla. Huipputulosten saavuttamiseksi Brillin tunnistin voi siis joissakin tapauksissa vaatia ainestokohtaista hienosäätöä. Toisaalta \citet{brill1992} huomauttaa, ettei sääntörunkojen laatimisessa tarvitse olla erityisen varovainen, sillä huonot sääntörungot eivät heikennä tunnistustarkkuutta: jos sääntörunko ei päde aineistoon, sen pohjalta ei luoda yhtään sääntöä. Täten erilaisten sääntölaajennusten kokeileminen on helppoa.

Brillin tunnistimen on myös havaittu olevan kohtalaisen immuuni ylisovittamiselle \citep{ramshaw1994}. Ylisovittaminen (engl. \textit{overfitting}) tarkoittaa tilannetta, missä luotu malli kuvastaa hyvin harjoitusaineistoa, muttei enää päde laajemmalle aineistolle. Brillin tunnistin minimoi ylisovittamisen riskiä hylkäämällä ne säännöt, jotka esiintyvät tiettyä raja-arvoa harvemmin. Tämän ominaisuuden perusteella voidaan spekuloida, että tunnistin suoriutuu hyvin myös todellisissa käyttötapauksissa.

Yksi Brillin tunnistimen puutteista on se, että sen tulosten varmuus ei ole suoraan määritettävissä. Tilastollisten tunnistimien tuloksiin liittyy aina todennäköisyysarvo, jonka perusteella tunnistamisen onnistumista voidaan arvioida; Brillin tunnistin taas asettaa jokaiselle sanalle aina yhden sanaluokan ottamatta kantaa todennäköisyyksiin. Todennäköisyysarvot ovat hyödyllisiä useissa eri tilanteissa: esimerkiksi jos tunnistin ei pysty käsittelemään jotakin aineiston osaa tarpeeksi suurella varmuudella, voidaan yrittää samaa jollakin toisella tunnistimella ja käyttää sitä tulosta, jolla on suurempi todennäköisyys. Brillin tunnistin ei --- ilman muokkauksia --- pysty toimimaan osana tällaista järjestelmää. 

Brillin tunnistimen toinen merkittävä epäkohta on se, että tunnistimen tarkkuus --- vaikkakin aikanaan ennätyksellinen --- on jäänyt jälkeen nykyisistä tilastollisista tunnistimista. Esimerkiksi \citet{spoustova2009} sekä \citet{sogaard2011} ovat saavuttaneet koetilanteissa noin prosenttiyksikön verran parempia tarkkuustuloksia, mikä tarkoittaa noin 20\% vähennystä tunnistusvirheiden määrässä. Erityisesti tuntemattomien sanojen oikein tunnistaminen on Brillin tunnistimelle ongelmallista \citep{schneider1998}. Varsinaisesta tilastollisten tunnistusmenetelmien läpimurrosta ei välttämättä kuitenkaan voida puhua, sillä edellä mainittu 20\% vähennys tunnistusvirheissä on vienyt lähes 20 vuotta. \citet{brill1995} väittääkin, että jos aineistopohjaisessa luonnollisten kielten käsittelyssä halutaan saavuttaa edistysaskeleita, on pyrittävä ymmärtämään itse kieltä tilastollisten rinnakkaisilmiöiden sijaan. Väitettä tukee havainto siitä, ettei tilastollisilla menetelmillä ole virheanalyysin perusteella odotettavissa suuria korotuksia nykyiseen sanaluokkien tunnistustarkkuuteen \citep{manning2011}.   


\chapter{Tilastolliset menetelmät}

Edellisestä sääntöpohjaisesta menetelmästä poiketen useimmat nykyiset sanaluokkien tunnistajat perustuvat tilastollisiin menetelmiin. Tilastollisissa sanaluokkien tunnistusmenetelmissä tavoitteena on löytää kullekin lauseelle sitä todennäköisimmin vastaava sanaluokkasarja:
\begin{align}
\argmax{t_1 \ldots t_n} p(w_1, w_2, \ldots, w_n,\: t_1, t_2, \ldots, t_n)
\label{statisticalproblem}
\end{align}
missä $p$ ilmaisee todennäköisyyden sille, että jokin lause $ w_1 \ldots w_n $ esiintyy jonkin sanaluokkasarjan $ t_1 \ldots t_n $ yhteydessä. Mahdollisten sanaluokkasarjojen määrä kuitenkin kasvaa eksponentiaalisesti sanojen ja sanaluokkien määrän mukaan, jolloin maksimiarvon ratkaiseminen naiivisti on epätehokasta.

Tilastolliset menetelmät voidaan vuorostaan jakaa diskriminatiivisiin ja generatiivisiin malleihin. Diskriminatiiviset mallit käsittelevät suoraan todennäköisyyttä $P(y|x)$, eli ne eivät ota kantaa syötteeseen $x$. Generatiiviset mallit puolestaan käsittelevät koko yhteisjakaumaa $P(x,y)$, josta todennäköisyys $P(y|x)$ johdetaan Bayesin säännön avulla. Intuition mukaan diskriminatiivinen malli on generatiivista mallia tehokkaampi, sillä yhteisjakauman mallintaminen on laskennallisesti vaativampaa kuin ehdollisen jakauman mallintaminen. \citetalias{ng2002} kuitenkin osoittavat, ettei tämä välttämättä aina pidä paikkaansa: sanaluokkien tunnistamiseen onkin olemassa kumpaankin malliin perustuvia tehokkaita ratkaisuja. Tässä tutkielmassa käsitellään generatiiviseen Markovin piilomalliin perustuvaa tunnistinta; diskriminatiivisen tunnistimen on esittänyt muun muassa \citet{ratnaparkhi1996}.

\section{Markovin malli}

Markovin malli \citep[mm.][]{rabiner1989} kuvaa sellaista stokastista prosessia, joka toteuttaa niin sanotun Markov-ominaisuuden: seuraava tila riippuu aina vain $N$:stä edeltävästä tilasta. Markov-ominaisuus on siis eräänlainen riippumattomuusoletus, joka yksinkertaistaa stokastisen prosessin tilan estimointia rajoittamalla tilasiirtymien historian määrää. $N$:nen asteen Markov-ominaisuuden toimiessa esimerkiksi todennäköisyys
\begin{align}
P(x_k | x_1, \ldots, x_{k-1})
\end{align}
voidaan laskea huomattavasti yksinkertaisemmin tarkastelemalla vain $N$:ää edellistä tilaa:
\begin{align}
P(x_k | x_{k - N }, \ldots, x_{k-1})
\end{align}

Markov-ominaisuudesta puhuttaessa on yleensä kyse juuri ensimmäisen asteen Markov-ominaisuudesta, jolloin $N=1$. Käytännössä tämä tarkoittaa sitä, että tarkastellaan jotakin kahta peräkkäistä tilaa --- nykyistä sekä tulevaa. Markov-ominaisuutta voidaan kuitenkin laajentaa myös korkeampiin asteisiin, jolloin myös tarkasteltavien tilasarjojen pituudet kasvavat. Sanaluokkia tunnistaessa näitä tilasarjoja vastaavat n:n peräkkäisen sanaluokan sarjat, eli n-grammit.   

Markovin mallin hyödyllisyyttä rajoittaa se, että malli ei pysty itsessään mallintamaan prosesseja, joiden tilat eivät ole suoraan havaittavissa. Useimmissa mielenkiintoisissa tapauksissa prosessin tilat eivät kuitenkaan suoraan vastaa havaintoja, eli prosessin tila --- vaikkakin havainnosta riippuvainen --- on piilotettu: esimerkiksi sanaluokkien tunnistamisongelmassa havainto (sana) on tiedossa, tila (sanaluokka) on riippuvainen havainnosta, mutta tila itsessään ei ole tiedossa. Tällöin Markovin malli tulee laajentaa Markovin piilomalliksi, jossa havainto on aina sitä vastaavan tilan todennäköisyysfunktio. \citep{rabiner1989}

\section{Tunnistusongelma Markovin piilomallina}

Markovin piilomallit hyödyntävät yhteisjakauman laskusääntöä $P(x,y) = P(y)P(x|y)$. Tällöin edellä mainittu funktio $p$ kaavassa \eqref{statisticalproblem} voidaan kuvata muodossa
\begin{align}
\hphantom{=} & p(w_1, w_2, \ldots, w_n,\: t_1, t_2, \ldots, t_n) \\
= & p(t_1, t_2, \ldots, t_n)\:p(w_1, w_2, \ldots, w_n|t_1, t_2, \ldots, t_n) \\
= & \prod_{i=1}^{n+1} q(t_i | t_{i-2}, t_{i-1}) \prod_{i=1}^{n}e(w_i | t_i)
\end{align}
missä $t_0$ ja $t_{-1}$ ovat lauseen alkuun lisättyjä alkusanaluokkia, ja $t_{n+1}$ on päätemerkkisanaluokka. Mallin ensimmäinen parametri
\begin{align}
q(t_i | t_{i-2}, t_{i-1})
\end{align}
laskee todennäköisyyden sanaluokalle $t_i$, kun kaksi edeltävää sanaluokkaa ovat $t_{i-1}$ ja $t_{i-2}$. Parametri voidaan myös mieltää todennäköisyytenä trigrammille $t_{i-2}, t_{i-1}, t_i $. Tästä huomataan, että kyseessä on toisen asteen Markovin piilomalli. Mallin toinen parametri
\begin{align}
e(w_i | t_i)
\end{align}
laskee todennäköisyyden sille, että sana $w_i$ esiintyy sanaluokan $t_i$ yhteydessä. \citep{brants2000}

\subsection{Parametrien estimointi}

Yksinkertaisimmillaan parametri $q(t_i|t_{i-2},t_{i-1})$ voidaan estimoida laskemalla
\begin{align}
q(t_i|t_{i-2},t_{i-1}) = \frac{f(t_{i-2},t_{i-1},t_i)}{f(t_{i-1},t_{i-1})}
\end{align}
missä funktio $f$ merkitsee annetun n-grammin lukumäärää harjoitusaineistossa. \citet{brants2000} kuitenkin osoittaa, että datan harvuuden vuoksi tällainen estimaatti ei ole käyttökelpoinen: laajassakaan harjoitusaineistossa ei ole tarpeeksi montaa kappaletta kutakin eri trigrammia. Lisäksi osa trigrammeista $t_{i-2},t_{i-1},t_i$ ovat väistämättä sellaisia, että $f(t_{i-2},t_{i-1},t_i) = 0$, jolloin koko sarjan $t_1 \ldots t_n$ todennäköisyys on $0$. Luotettavampi tapa estimoida parametria $q$ on hyödyntää trigrammien lisäksi myös harjoitusaineistosta johdettujen uni- ja bigrammien suhteellisia frekvenssejä:
\begin{align}
Unigrammi&: P(t_i) = \frac{f(t_i)}{M} \\
Bigrammi&: P(t_i | t_{i-1}) = \frac{f(t_{i-1}, t_i)}{f(t_{i-1})} \\
Trigrammi&: P(t_i | t_{i-2}, t_{i-1}) = \frac{f(t_{i-2},t_{i-1},t_i)}{f(t_{i-2},t_{i-1})}
\end{align}
missä $M$ merkitsee harjoitusaineiston sanojen kokonaislukumäärää. Nyt parametrin $q$ arvoa voidaan silottaa interpoloimalla edellä mainittuja n-grammeja:
\begin{align}
q(t_i | t_{i-2}, t_{i-1}) = \lambda_1 P(t_i) + \lambda_2 P(t_i | t_{i-1}) + \lambda_3 P(t_i | t_{i-2}, t_{i-1})
\end{align}
missä $\lambda_1+\lambda_2+\lambda_3 = 1$ ja $\lambda_1,\lambda_2,\lambda_3 \geq 0$. \citep{brants2000}

Vastaavasti todennäköisyys $e$ voidaan estimoida vertaamalla sana-sanaluokka-yhdistelmän frekvenssiä pelkän sanaluokan frekvenssiin:
\begin{align}
e(w_i|t_i) = \frac{f(w_i, t_i)}{f(t_i)}
\label{hmm_param_e}
\end{align}

Edellisten estimaattien myötä alkuperäinen tunnistusongelma kaavassa \eqref{statisticalproblem} on valmis ratkaistavaksi:
\begin{align}
\hphantom{=} & \argmax{t_1 \ldots t_n} p(w_1, w_2, \ldots, w_n,\: t_1, t_2, \ldots, t_n) \\
= & \argmax{t_1 \ldots t_n} \left(\prod_{i=1}^{n+1} q(t_i | t_{i-2}, t_{i-1}) \prod_{i=1}^{n}e(w_i | t_i) \right)
\end{align}
TODO: Maininta Viterbi-algoritmista \citep{viterbi1967}.

\subsection{Tuntemattomien sanojen käsittely}

Todennäköisyyden $e$ estimaatti \eqref{hmm_param_e} ei ole luotettava, jos jokin kohdattu sana ei esiinny harjoitusaineistossa kertaakaan. Tällöin, jos sana $w_i$ on tuntematon, on $e(w_i|t_i)=0$ millä tahansa sanaluokalla $t_i$. Samoin $p(w_1, w_2, \ldots, w_n, t_1, t_2, \ldots, t_n) = 0$, jos yksikään sanoista $w_i \ldots w_n$ on tuntematon. Jotta vältytään mallin rikkovilta nollaestimaateilta, on tuntemattomien sanojen kohdalla sovellettava jonkinlaista poikkeuskäsittelyä.

Yksinkertaisin ratkaisu on määrätä tuntemattoman sanalle aina harjoitusaineiston yleisin sanaluokka, yleensä substantiivi. Joitain kieliä --- kuten englantia --- tulkittaessa voidaan saavuttaa parempia tuloksia suffiksianalyysin \citep{samuelsson1993} avulla. Tällöin tarkoituksena on hyödyntää sitä seikkaa, että sanan pääte on usein vahva indikaattori sen sanaluokasta. Lisäksi \citet{toutanova2003} ovat esittäneet, kuinka diskriminatiivisia log-lineaarisia malleja voidaan hyödyntää tuntemattomien sanojen käsittelyssä.

\citet{bikel1999} esittivät vaihtoehtoisen, pseudosanoihin perustuvan menetelmän tuntemattomien sanojen käsittelylle. Menetelmän perusajatuksena on korvata tunnistettavan aineiston kukin tuntematon sana jollakin pseudosanalla, joita on rajallinen määrä. Myös kaikki harvinaiset (vähemmän kuin 5 esiintymää) sanat voidaan korvata pseudosanoilla. Korvaava pseudosana määräytyy aina tuntemattoman sanan ominaisuuksien mukaan: esimerkiksi \textit{isoAlkukirjain}, \textit{lauseenEnsimmäinenSana} sekä \textit{neljäNumeroa} ovat tyypillisiä pseudosanoja. Nyt kun harjoitusaineiston harvinaiset sanat korvataan vastaavilla pseudosanoilla, voidaan tunnistettavan aineiston pseudosanoja käsitellä samoin kuin tavallisia sanoja.


\section{Tilastollisen tunnistimen arviointi}

1. Trigrammi-oletus on melko vahva ja lingvistisesti naiivi --- johtaa kuitenkin käytännössä hyödyllisiin malleihin. CDC \citep{heckerman2000, toutanova2003}.

2. Ei poimi sanojen välisiä suhteita, pelkästään sanaluokkien.

3. Jää jälkeen nykyisistä SOTA-taggereista, mutta pärjää hyvin web-tekstissä \citep{giesbrecht2009}.

\citet{brill1992} huomauttaakin, että tilastolliset tunnistajat saavuttavat korkean tunnistamistarkkuuden kiinnittämättä varsinaisesti huomiota aineiston taustalla olevaan kieliopilliseen rakenteeseen. Hän laskee tilastollisten menetelmien puutteeksi sen, että ne poimivat aineistosta lingvistisen informaation sijaan vain suuren määrän vaikeselkoisia tilastoja.


\chapter{Yhteenveto}

TODO Yhteenvedossa kerrataan työn pääkohdat lyhyehkösti johtopäätöksiä tehden. Siinä voi myös esittää pohdintoja siitä, minkälaisia tutkimuksia aiheesta voisi jatkossa tehdä. viittaa kirjallisuuskatsauksen tarkoitukseen ja kertoo ''päätulokset''. Vastataan tutkimuskysymykseen.




\begin{thebibliography}{}

\bibitem[Bikel ym.(1999)]{bikel1999}
Bikel, D. M., Schwartz, R., \& Weischedel, R. M. 1999. \textit{An algorithm that learns what's in a name}. Machine learning, 34(1-3), s.~211--231.

\bibitem[Brants(2000)]{brants2000}
Brants, T. 2000. \textit{TnT - A statistical part-of-speech tagger}. Proceedings of the 6th Applied NLP Conference (ANLP).

\bibitem[Brill(1992)]{brill1992}
Brill, E. 1992. \textit{A simple rule-based part of speech tagger}. Proceedings of the 3rd conference on Applied Computational Linguistics, ACL, Trento, Italy.

\bibitem[Brill(1994)]{brill1994}
Brill, E. 1994. \textit{Some advances in transformation-based part of speech tagging}. AAAI 1994, s.~722--727.

\bibitem[Brill(1995)]{brill1995}
Brill, E. 1995. \textit{Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging}. Computational linguistics, 21(4), s.~543--565.

\bibitem[Charniak ym.(1993)]{charniak1993}
Charniak, E., Hendrickson, C., Jacobson, N., \& Perkowitz, M. 1993. \textit{Equations for part-of-speech tagging}. Proceedings of AAAI-93, s.~784--789.

\bibitem[Cutting ym.(1992)]{cutting1992}
Cutting, D., Kupiec, J., Pedersen, J. \& Sibun, P. 1992. \textit{A Practical Part-of-Speech Tagger}. Proceedings of the 3rd conference on Applied Natural Language Processing, s.~133--140.

\bibitem[DeRose(1988)]{derose1988}
DeRose, S. J. 1988. \textit{Grammatical category disambiguation by statistical optimization}. Computational Linguistics, 14(1), s.~31--39.

\bibitem[Giesbrecht \& Evert(2009)]{giesbrecht2009}
Giesbrecht, E., \& Evert, S. 2009. \textit{Is Part-of-Speech tagging a solved task? An evaluation of POS taggers for the German Web as Corpus}. Proceedings of the 5th Web as Corpus Workshop (WAC5), s.~ 27--35.

\bibitem[Greene \& Rubin(1971)]{greene1971}
Greene, B. B., \& Rubin, G. M. 1971. \textit{Automatic grammatical tagging of English}. Department of Linguistics, Brown University, 1971.

\bibitem[Heckerman ym.(2000)]{heckerman2000}
Heckerman, D., Chickering, D. M., Meek, C., Rounthwaite, R. \& Kadie, C. M. 2000. \textit{Dependency networks for inference, collaborative filtering and data visualization}.
Journal of Machine Learning Research, 1(1), s.~49-75.

\bibitem[Manning(2011)]{manning2011}
Manning, C. D. 2011. \textit{Part-of-Speech Tagging from 97\% to 100\%: Is It Time for Some Linguistics?} Proceedings of the 12th international conference on Computational linguistics and intelligent text processing, 1, s.~171--189.

\bibitem[Manning \& Sch\"{u}tze(1999)]{manning1999}
Manning, C. D. \& Sch\"{u}tze, H. 1999. \textit{Foundations of statistical natural language processing}.
Cambridge, MA. MIT Press

\bibitem[Marcus ym.(1993)]{marcus1993}
Marcus, M. P., Marcinkiewicz, M. \& Santorini, B. 1993. \textit{Building a large annotated corpus of English: the Penn treebank}. Computational Linguistics, 19(2), s.~313-330.

\bibitem[Megyesi(1999)]{megyesi1999}
Megyesi, B. 1999. \textit{Improving Brill’s POS tagger for an agglutinative language}. Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, s.~275--284.

\bibitem[Ng \& Jordan(2002)]{ng2002}
Ng, A. Y. \& Jordan, M. 2002. \textit{On Discriminative vs. Generative Classifiers: A comparison of logistic regression and Naive Bayes}. In NIPS 14.

\bibitem[Ngai \& Florian(2001)]{ngai2001}
Ngai, G. \& Florian, R. 2001. \textit{Transformation-based learning in the fast lane}. Proceedings of the 2nd meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, s.~1--8.

\bibitem[Rabiner(1989)]{rabiner1989}
Rabiner, L. R. 1989. \textit{A tutorial on Hidden Markov Models and selected applications in speech recognition}. Proceedings of the IEEE, 77(2), s.~257-285.

\bibitem[Ramshaw \& Marcus(1994)]{ramshaw1994}
Ramshaw, L., \& Marcus, M. 1994. \textit{Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging}. Proceedings of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language, s.~128--135.

\bibitem[Ratnaparkhi(1996)]{ratnaparkhi1996}
Ratnaparkhi, A. 1996. \textit{A maximum entropy model for part-of-speech tagging}. Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP), University of Pennsylvania.

\bibitem[Roche \& Schabes(1995)]{roche1995}
Roche, E., \& Schabes, Y. 1995. \textit{Deterministic part-of-speech tagging with finite-state transducers}. Computational linguistics, 21(2), s.~227--253.

\bibitem[Samuelsson(1993)]{samuelsson1993}
Samuelsson, C. 1993. \textit{Morphological tagging based entirely on Bayesian inference}. Proceedings of the 9th Nordic Conference on Computational Linguistics NODALIDA-93.

\bibitem[Schneider \& Volk(1998)]{schneider1998}
Schneider, G., \& Volk, M. 1998. \textit{Adding manual constraints and lexical look-up to a Brill-tagger for German}. Proceedings of the ESSLLI-98 Workshop on Recent Advances in Corpus Annotation, Saarbrücken.

\bibitem[Shen ym.(2007)]{shen2007}
Shen, L., Satta, G. \& Joshi, A. 2007. \textit{Guided learning for bidirectional sequence classification}. In: ACL 2007. (2007)

\bibitem[Spoustova ym.(2009)]{spoustova2009}
Spoustova, D.j., Hajic, J., Raab, J. \& Spousta, M. 2009. \textit{Semi-supervised training for the averaged perceptron POS tagger}. Proceedings of the 12th Conference of the
European Chapter of the ACL (EACL 2009), s.~763-711.

\bibitem[Søgaard(2011)]{sogaard2011}
Søgaard, A. 2011. \textit{Semi-supervised condensed nearest neighbor for part-of-speech tagging}. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, 2, s.~48--52. Association for Computational Linguistics.

\bibitem[Toutanova ym.(2003)]{toutanova2003}
Toutanova, K., Klein, D., Manning, C. D., \& Singer, Y. 2003. \textit{Feature-rich part-of-speech tagging with a cyclic dependency network}. Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, 1, s.~173--180. Association for Computational Linguistics.

\bibitem[Tseng ym.(2005)]{tseng2005}
Tseng, H., Jurafsky, D. \& Manning, C. 2005. \textit{Morphological features help POS tagging of unknown words across language varities}. Proceedings of the 4th SIGHAN bakeoff.

\bibitem[Viterbi(1967)]{viterbi1967}
Viterbi, A. 1967. \textit{Error bounds for convolutional codes and an asymptotically optimum decoding algorithm}. Information Theory, IEEE Transactions on, 13(2), s.~260--269.

\bibitem[Volk \& Schneider(1998)]{volk1998}
Volk, M. \& Schneider, G. 1998. \textit{Comparing a statistical and a rule-based tagger for German}. Computers, Linguistics, and Phonetics between Language and Speech. Proceedings
of the 4th Conference on Natural Language Processing - KONVENS-98, s.~125--137.

\end{thebibliography}

\end{document}
